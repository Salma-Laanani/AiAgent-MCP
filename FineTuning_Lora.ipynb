{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqBX55brT7RwpI8I+Ksn6d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "74eb49d48f1d4b3f93c76666264e1cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e215a67c15bd4e6690cb079d2cac32eb",
              "IPY_MODEL_ea1d9c2df3d24bdaad88cf77acb339a8",
              "IPY_MODEL_c084467944b843c9875eab86b6aebb9f"
            ],
            "layout": "IPY_MODEL_3e499db25f63428294e3db0d1d12083c"
          }
        },
        "e215a67c15bd4e6690cb079d2cac32eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb617bdc9c204ea69d282d20cbd932f1",
            "placeholder": "​",
            "style": "IPY_MODEL_f5c8c6c58e3546aa87f0eebbdc1042ed",
            "value": "tokenizer_config.json: "
          }
        },
        "ea1d9c2df3d24bdaad88cf77acb339a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c6c80a1c2524cda9817a69436d83c58",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_595b7569ac0d4e33a67db27e5eebfd73",
            "value": 1
          }
        },
        "c084467944b843c9875eab86b6aebb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d0f9e58e3e49a9b8b074454c3e499a",
            "placeholder": "​",
            "style": "IPY_MODEL_b31bac2e4dc44ec99dccf9aef73452c1",
            "value": " 50.6k/? [00:00&lt;00:00, 4.70MB/s]"
          }
        },
        "3e499db25f63428294e3db0d1d12083c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb617bdc9c204ea69d282d20cbd932f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c8c6c58e3546aa87f0eebbdc1042ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c6c80a1c2524cda9817a69436d83c58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "595b7569ac0d4e33a67db27e5eebfd73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65d0f9e58e3e49a9b8b074454c3e499a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b31bac2e4dc44ec99dccf9aef73452c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e156f4bc59724faca492cb5754fd2364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_644e862ee9a84549bb90cce6ceb0d636",
              "IPY_MODEL_4770956e80b54eaf9e2a8f44fa916373",
              "IPY_MODEL_6ed96c9dc5d34b2eb630845be22a42a8"
            ],
            "layout": "IPY_MODEL_ea1a63a3e03e4796ba93e3c1eb655a64"
          }
        },
        "644e862ee9a84549bb90cce6ceb0d636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88f22ed5ce30421b854b8a82bcda017b",
            "placeholder": "​",
            "style": "IPY_MODEL_f522ddc6c356454e9de2ca00e15c781a",
            "value": "tokenizer.json: 100%"
          }
        },
        "4770956e80b54eaf9e2a8f44fa916373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7d27ca7976e47169eae53900157b4f6",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a72dd73b72764591adf3ef03153440ce",
            "value": 17209920
          }
        },
        "6ed96c9dc5d34b2eb630845be22a42a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e06c8098cea44fd9560db143c6d2ce5",
            "placeholder": "​",
            "style": "IPY_MODEL_9f5c8c0943ff4f189d5eb35e33f5e3eb",
            "value": " 17.2M/17.2M [00:00&lt;00:00, 26.8MB/s]"
          }
        },
        "ea1a63a3e03e4796ba93e3c1eb655a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88f22ed5ce30421b854b8a82bcda017b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f522ddc6c356454e9de2ca00e15c781a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7d27ca7976e47169eae53900157b4f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a72dd73b72764591adf3ef03153440ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e06c8098cea44fd9560db143c6d2ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5c8c0943ff4f189d5eb35e33f5e3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62c7ab0b5c24e5bbea6e211f951b000": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2e6dd2c901d4a899f8300b819c0e7e4",
              "IPY_MODEL_916d95c2cd6a410bb98438d87e15af98",
              "IPY_MODEL_2d7d4d1959914cd2b442087f8ece746c"
            ],
            "layout": "IPY_MODEL_6ec91e649e9e48b0b90534af787de626"
          }
        },
        "c2e6dd2c901d4a899f8300b819c0e7e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b87184770441108bc657e492cfe0e0",
            "placeholder": "​",
            "style": "IPY_MODEL_aca1c9cf7fbf4c78aa132aa4a5a9089b",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "916d95c2cd6a410bb98438d87e15af98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a3dbc98a30d404bbe26bafe228e186b",
            "max": 459,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73eac46e986b49f4b0ba210c649b38c6",
            "value": 459
          }
        },
        "2d7d4d1959914cd2b442087f8ece746c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb9d87d6eda489abe82d9d052c98c70",
            "placeholder": "​",
            "style": "IPY_MODEL_0a94c2b958d843c3b7729d273570b6bf",
            "value": " 459/459 [00:00&lt;00:00, 29.8kB/s]"
          }
        },
        "6ec91e649e9e48b0b90534af787de626": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b87184770441108bc657e492cfe0e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca1c9cf7fbf4c78aa132aa4a5a9089b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a3dbc98a30d404bbe26bafe228e186b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73eac46e986b49f4b0ba210c649b38c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cb9d87d6eda489abe82d9d052c98c70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a94c2b958d843c3b7729d273570b6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc5cd28347d24a8f9c83cd90823d3a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eca51ed1d0dc4412b5a7562a1ccf7b31",
              "IPY_MODEL_8c2eefdc6ca8453aa0f3fe6909dfc813",
              "IPY_MODEL_38cfca3e1c104bb6aa9717879214bf6a"
            ],
            "layout": "IPY_MODEL_9827959cb4434c4887de0080f1275a7d"
          }
        },
        "eca51ed1d0dc4412b5a7562a1ccf7b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b937f369dff14fdca5b2c8aaff8370d1",
            "placeholder": "​",
            "style": "IPY_MODEL_d6bb808b233e47099cdb1f92ccbbcf86",
            "value": "config.json: 100%"
          }
        },
        "8c2eefdc6ca8453aa0f3fe6909dfc813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed8601207d64471ad327e329274709d",
            "max": 889,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9c06209a56a483e833ff1bd0f329314",
            "value": 889
          }
        },
        "38cfca3e1c104bb6aa9717879214bf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_744ddeeb4c5049e3b76c73bf96ec2046",
            "placeholder": "​",
            "style": "IPY_MODEL_6ae2e185baad40d8872587349bd4512d",
            "value": " 889/889 [00:00&lt;00:00, 113kB/s]"
          }
        },
        "9827959cb4434c4887de0080f1275a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b937f369dff14fdca5b2c8aaff8370d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6bb808b233e47099cdb1f92ccbbcf86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ed8601207d64471ad327e329274709d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9c06209a56a483e833ff1bd0f329314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "744ddeeb4c5049e3b76c73bf96ec2046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae2e185baad40d8872587349bd4512d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24dcc0ab1c364229b32bf6471cc895fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2920d516269942ffa5bf25797306b0c5",
              "IPY_MODEL_775894f4d36f41cbb30330af6dd7993c",
              "IPY_MODEL_a0462676639a4b2b8e83fb1440a1bb7f"
            ],
            "layout": "IPY_MODEL_bfe317dba6a849bfa4b4506f80031936"
          }
        },
        "2920d516269942ffa5bf25797306b0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98e88fb6015413795e6ead884a1e92a",
            "placeholder": "​",
            "style": "IPY_MODEL_34e03e722aa941eeb47648ac4c03bed2",
            "value": "model.safetensors: 100%"
          }
        },
        "775894f4d36f41cbb30330af6dd7993c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84523bb27c5a4f1aae66ed3201a1954b",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_908d1473d11c4a28973014afa590a72d",
            "value": 2471645608
          }
        },
        "a0462676639a4b2b8e83fb1440a1bb7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13eeae2f365b434e8f0c34cb0a57fc7f",
            "placeholder": "​",
            "style": "IPY_MODEL_bbf7deef879140abac68618cab227151",
            "value": " 2.47G/2.47G [00:20&lt;00:00, 234MB/s]"
          }
        },
        "bfe317dba6a849bfa4b4506f80031936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98e88fb6015413795e6ead884a1e92a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e03e722aa941eeb47648ac4c03bed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84523bb27c5a4f1aae66ed3201a1954b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "908d1473d11c4a28973014afa590a72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13eeae2f365b434e8f0c34cb0a57fc7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf7deef879140abac68618cab227151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59ac4efc5cf54036a627b55694eb79e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aab14732c9c148a49caad2a311dbfd38",
              "IPY_MODEL_e4cc90898bfa4524af3bc523474395ec",
              "IPY_MODEL_99b6502ded9443e08781578ff5e42fcb"
            ],
            "layout": "IPY_MODEL_cf4d701c549c47a18722e36e74f2a3e5"
          }
        },
        "aab14732c9c148a49caad2a311dbfd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_373c7b387e23476b9d08d9b5437e19c8",
            "placeholder": "​",
            "style": "IPY_MODEL_5fae540bc551428da7ef65f089aef459",
            "value": "generation_config.json: 100%"
          }
        },
        "e4cc90898bfa4524af3bc523474395ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1561868578fb4523b9b896d6f5cbe945",
            "max": 230,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4cc8ebdd5b64f8aba7413b0693a71af",
            "value": 230
          }
        },
        "99b6502ded9443e08781578ff5e42fcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f637337b648047199c56294e23876680",
            "placeholder": "​",
            "style": "IPY_MODEL_4abf42418f5144cfb314a9f9747bc040",
            "value": " 230/230 [00:00&lt;00:00, 21.6kB/s]"
          }
        },
        "cf4d701c549c47a18722e36e74f2a3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "373c7b387e23476b9d08d9b5437e19c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fae540bc551428da7ef65f089aef459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1561868578fb4523b9b896d6f5cbe945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4cc8ebdd5b64f8aba7413b0693a71af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f637337b648047199c56294e23876680": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4abf42418f5144cfb314a9f9747bc040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0115b7f1efd64358b3d5473c28a8eb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_736e6267bf20439a86d3cf44d593d66d",
              "IPY_MODEL_6924ac252cb84d54a845cec65f231648",
              "IPY_MODEL_8e4159bbce7b490bac01cd44da3159a9"
            ],
            "layout": "IPY_MODEL_a27609574907484cba1c2c260faf02a2"
          }
        },
        "736e6267bf20439a86d3cf44d593d66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1923d8e3830e476ebdd5b2a742dae1ae",
            "placeholder": "​",
            "style": "IPY_MODEL_d3d1557a8583403883fc2e603bb3d67a",
            "value": "Map: 100%"
          }
        },
        "6924ac252cb84d54a845cec65f231648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46613bc3c90c4898af764ab9fb05a1ea",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_420daf15232448f39900846a509f57ca",
            "value": 160
          }
        },
        "8e4159bbce7b490bac01cd44da3159a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01ff3ae10cc24db7b919f91f6becd381",
            "placeholder": "​",
            "style": "IPY_MODEL_0f61f0673d60413cbd1d68ccfb5cc241",
            "value": " 160/160 [00:00&lt;00:00, 851.83 examples/s]"
          }
        },
        "a27609574907484cba1c2c260faf02a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1923d8e3830e476ebdd5b2a742dae1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d1557a8583403883fc2e603bb3d67a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46613bc3c90c4898af764ab9fb05a1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "420daf15232448f39900846a509f57ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01ff3ae10cc24db7b919f91f6becd381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f61f0673d60413cbd1d68ccfb5cc241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b26037d7799c45b9807773c80149b4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b7d6a12efbc45e0833772aa09a5ca73",
              "IPY_MODEL_2f66f1eff94047bda4b0983372eb959b",
              "IPY_MODEL_e6729801b49744ea8af5b9dc16c71cd7"
            ],
            "layout": "IPY_MODEL_6959abe1c31a4b1ba209abecff823257"
          }
        },
        "2b7d6a12efbc45e0833772aa09a5ca73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14bee0c8997c48f59238c8b06ce3f9d3",
            "placeholder": "​",
            "style": "IPY_MODEL_ff1b7098d7bf4693a95467b720a76fbd",
            "value": "Map: 100%"
          }
        },
        "2f66f1eff94047bda4b0983372eb959b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2919e28bc7344b7a9e1dc3a45f443635",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4f2c6f052a042dcb3082bb9e92480d4",
            "value": 40
          }
        },
        "e6729801b49744ea8af5b9dc16c71cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_637e897bfc224f7b8078f2c6e79ed741",
            "placeholder": "​",
            "style": "IPY_MODEL_33767cc4b711461dba9c641c7967fc1d",
            "value": " 40/40 [00:00&lt;00:00, 837.75 examples/s]"
          }
        },
        "6959abe1c31a4b1ba209abecff823257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14bee0c8997c48f59238c8b06ce3f9d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1b7098d7bf4693a95467b720a76fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2919e28bc7344b7a9e1dc3a45f443635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f2c6f052a042dcb3082bb9e92480d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "637e897bfc224f7b8078f2c6e79ed741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33767cc4b711461dba9c641c7967fc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bb47d034a0b4af785596cbd95e855db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f6c5ba21c14442fa95932bd4934910f",
              "IPY_MODEL_49a4de33d49243999c935ec2bbaac476",
              "IPY_MODEL_0926b83473d541fe95ff680befe7da6a"
            ],
            "layout": "IPY_MODEL_3660c55579304012b682de969a71ba2c"
          }
        },
        "0f6c5ba21c14442fa95932bd4934910f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7535ada77e6548d08b4bf06b7f829715",
            "placeholder": "​",
            "style": "IPY_MODEL_ba167eacb81f437eaeb1abb9fcdcb471",
            "value": "Map: 100%"
          }
        },
        "49a4de33d49243999c935ec2bbaac476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c436858fced940459b423995de871dc3",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be0426ce00b74667a8a5f28fa3305f77",
            "value": 160
          }
        },
        "0926b83473d541fe95ff680befe7da6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cc40c37c2bf488dbc21a67c63718f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_c5cf029104bb47ad84c2cb8d42b83ad4",
            "value": " 160/160 [00:00&lt;00:00, 1070.79 examples/s]"
          }
        },
        "3660c55579304012b682de969a71ba2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7535ada77e6548d08b4bf06b7f829715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba167eacb81f437eaeb1abb9fcdcb471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c436858fced940459b423995de871dc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be0426ce00b74667a8a5f28fa3305f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cc40c37c2bf488dbc21a67c63718f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cf029104bb47ad84c2cb8d42b83ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98acec97afbf4eb4a678fb1372c81025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b21d851c9c5f4fe4ba269a2af0bdf04e",
              "IPY_MODEL_e1ced0da730044dfae4bd6ef9b901e32",
              "IPY_MODEL_cfd1d2414d5042df8214fec123a42101"
            ],
            "layout": "IPY_MODEL_3a7338e7abc147b5b5ddd1bec7beba02"
          }
        },
        "b21d851c9c5f4fe4ba269a2af0bdf04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13c74d311786495caf38c4659db8be44",
            "placeholder": "​",
            "style": "IPY_MODEL_29c2fd6f847944a8944c03e4e3c0cf43",
            "value": "Map: 100%"
          }
        },
        "e1ced0da730044dfae4bd6ef9b901e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8722996dd5d64b1a950a49fe6b9e2a22",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a776755f9e8c492e9988449abb9af9c4",
            "value": 40
          }
        },
        "cfd1d2414d5042df8214fec123a42101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b80980b6124eef808d8944bf8a7646",
            "placeholder": "​",
            "style": "IPY_MODEL_065d6d8f5ae846f7874f2642d35abc65",
            "value": " 40/40 [00:00&lt;00:00, 198.97 examples/s]"
          }
        },
        "3a7338e7abc147b5b5ddd1bec7beba02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13c74d311786495caf38c4659db8be44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c2fd6f847944a8944c03e4e3c0cf43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8722996dd5d64b1a950a49fe6b9e2a22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a776755f9e8c492e9988449abb9af9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9b80980b6124eef808d8944bf8a7646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "065d6d8f5ae846f7874f2642d35abc65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d72cf071f5104d988502d966d50d4b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce14c0fe0f3145e4ac46405ea6e3e3a9",
              "IPY_MODEL_25a26e6c0aab4533ab51f844929e537d",
              "IPY_MODEL_463aea260cf64517ac29481b606bb6f5"
            ],
            "layout": "IPY_MODEL_3a7882abff934c4bb5ac651445bc63e7"
          }
        },
        "ce14c0fe0f3145e4ac46405ea6e3e3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ddf4187940c4c1397fa0beece5830d8",
            "placeholder": "​",
            "style": "IPY_MODEL_2a69bd8a0bb44e17930cfeda18404d19",
            "value": "Map: 100%"
          }
        },
        "25a26e6c0aab4533ab51f844929e537d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b384931ef7ca45008c8df0c875510659",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aa8f4bc5c7f4c4799abe0d464be5eb3",
            "value": 160
          }
        },
        "463aea260cf64517ac29481b606bb6f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e34871bbd0e438c974fa7fd74c3e6c3",
            "placeholder": "​",
            "style": "IPY_MODEL_49c97b6ee50044ae9c384b9425d286b3",
            "value": " 160/160 [00:00&lt;00:00, 2003.27 examples/s]"
          }
        },
        "3a7882abff934c4bb5ac651445bc63e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ddf4187940c4c1397fa0beece5830d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a69bd8a0bb44e17930cfeda18404d19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b384931ef7ca45008c8df0c875510659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aa8f4bc5c7f4c4799abe0d464be5eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e34871bbd0e438c974fa7fd74c3e6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49c97b6ee50044ae9c384b9425d286b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31a306430a684ed7af01427e0ce2b0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_650424c6758a4428bb5828f459714d4c",
              "IPY_MODEL_9fd9dba320e6461c8e4f87d60fb19579",
              "IPY_MODEL_8b52e8f179444690a95fd61c77c46a8a"
            ],
            "layout": "IPY_MODEL_52336000842c4bf9b54f45604285370d"
          }
        },
        "650424c6758a4428bb5828f459714d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_166cfe2226084ffe9a988bbba6cfa8ff",
            "placeholder": "​",
            "style": "IPY_MODEL_3701c4e674464d38942a8e483e7ea818",
            "value": "Map: 100%"
          }
        },
        "9fd9dba320e6461c8e4f87d60fb19579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1853eefda314cd4a12d3238c8cd8148",
            "max": 40,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b56b1a41d3ea4eea88296f9630946d81",
            "value": 40
          }
        },
        "8b52e8f179444690a95fd61c77c46a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ad6ec08d274ba1936877093c547e25",
            "placeholder": "​",
            "style": "IPY_MODEL_45668d78a41749838f517d71d872a459",
            "value": " 40/40 [00:00&lt;00:00, 818.52 examples/s]"
          }
        },
        "52336000842c4bf9b54f45604285370d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "166cfe2226084ffe9a988bbba6cfa8ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3701c4e674464d38942a8e483e7ea818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1853eefda314cd4a12d3238c8cd8148": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56b1a41d3ea4eea88296f9630946d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68ad6ec08d274ba1936877093c547e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45668d78a41749838f517d71d872a459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Salma-Laanani/AiAgent-MCP/blob/master/FineTuning_Lora.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# # 🚀 FINE-TUNING EMSI CHATBOT - Llama 3.2 avec LoRA\n",
        "# ## Dataset: Votre fichier emsi_dataset.json\n",
        "#\n",
        "# **Auteur** : Votre nom\n",
        "# **Date** : Aujourd'hui\n",
        "# **Objectif** : Fine-tuner Llama 3.2 pour répondre aux questions EMSI\n",
        "\n",
        "# %%\n",
        "# Étape 1.1 : Vérifier le GPU (CRUCIAL !)\n",
        "import torch\n",
        "print(f\"🎯 GPU disponible : {torch.cuda.is_available()}\")\n",
        "print(f\"🎯 GPU : {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'AUCUN'}\")\n",
        "print(f\"🎯 Mémoire GPU : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} Go\" if torch.cuda.is_available() else \"\")\n",
        "\n",
        "# Si pas de GPU -> Runtime -> Change runtime type -> GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kbPyO-40RCV",
        "outputId": "ae237b8f-8e4e-4f47-e33f-240807829161"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎯 GPU disponible : True\n",
            "🎯 GPU : Tesla T4\n",
            "🎯 Mémoire GPU : 15.83 Go\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 2 : Installation des dépendances\n",
        "!pip install -q transformers accelerate peft datasets bitsandbytes\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q sentencepiece protobuf\n",
        "!pip install -q scikit-learn\n",
        "\n",
        "print(\"✅ Toutes les bibliothèques sont installées !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijb9PtTX0mFU",
        "outputId": "d76c0342-a96d-48f6-c90c-45e6ce73aeb9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Toutes les bibliothèques sont installées !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 3 : Upload de votre dataset EMSI\n",
        "from google.colab import files\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "print(\"📤 UPLOADEZ VOTRE FICHIER emsi_dataset.json\")\n",
        "print(\"Cliquez sur 'Choose Files' et sélectionnez votre fichier\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Vérification\n",
        "dataset_filename = list(uploaded.keys())[0]\n",
        "print(f\"✅ Fichier uploadé : {dataset_filename}\")\n",
        "print(f\"📦 Taille : {len(uploaded[dataset_filename]) / 1024:.2f} Ko\")\n",
        "\n",
        "# Chargement et vérification\n",
        "with open(dataset_filename, 'r', encoding='utf-8') as f:\n",
        "    emsi_data = json.load(f)\n",
        "\n",
        "print(f\"🎯 Nombre d'exemples : {len(emsi_data)}\")\n",
        "print(\"\\n📝 Aperçu du premier exemple :\")\n",
        "print(json.dumps(emsi_data[0], indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "PuXX_GqI2mt_",
        "outputId": "dbdef728-e4b4-47d0-987b-6beaa3ed5cb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📤 UPLOADEZ VOTRE FICHIER emsi_dataset.json\n",
            "Cliquez sur 'Choose Files' et sélectionnez votre fichier\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4548d898-30ce-4c57-987b-8da293679266\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4548d898-30ce-4c57-987b-8da293679266\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving emsi_dataset.json to emsi_dataset.json\n",
            "✅ Fichier uploadé : emsi_dataset.json\n",
            "📦 Taille : 91.16 Ko\n",
            "🎯 Nombre d'exemples : 200\n",
            "\n",
            "📝 Aperçu du premier exemple :\n",
            "{\n",
            "  \"instruction\": \"Quand a été fondée l'EMSI ?\",\n",
            "  \"input\": \"Document officiel EMSI - Historique\",\n",
            "  \"output\": \"L'École Marocaine des Sciences de l'Ingénieur (EMSI) a été fondée en 1986 au Maroc.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 4 : Préparation du dataset pour l'entraînement\n",
        "from datasets import Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "\n",
        "print(\"🧹 Préparation du dataset...\")\n",
        "\n",
        "# Convertir en DataFrame\n",
        "df = pd.DataFrame(emsi_data)\n",
        "\n",
        "# Afficher les statistiques\n",
        "print(f\"📊 Statistiques du dataset :\")\n",
        "print(f\"   - Total exemples : {len(df)}\")\n",
        "print(f\"   - Colonnes : {list(df.columns)}\")\n",
        "print(f\"   - Exemples avec contexte : {df['input'].notna().sum()}\")\n",
        "\n",
        "# Vérifier les colonnes nécessaires\n",
        "required_columns = ['instruction', 'output']\n",
        "missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "if missing_columns:\n",
        "    print(f\"❌ Colonnes manquantes : {missing_columns}\")\n",
        "    print(\"Vérifiez votre dataset !\")\n",
        "else:\n",
        "    print(\"✅ Dataset correctement formaté\")\n",
        "\n",
        "# %%\n",
        "# Fonction de formatage pour l'entraînement\n",
        "def format_instruction(row):\n",
        "    \"\"\"Formate les exemples pour l'entraînement\"\"\"\n",
        "    instruction = row['instruction']\n",
        "    context = row.get('input', '')\n",
        "    response = row['output']\n",
        "\n",
        "    if context and str(context).strip():\n",
        "        return f\"### Instruction:\\n{instruction}\\n\\n### Contexte:\\n{context}\\n\\n### Réponse:\\n{response}\"\n",
        "    else:\n",
        "        return f\"### Instruction:\\n{instruction}\\n\\n### Réponse:\\n{response}\"\n",
        "\n",
        "# Appliquer le formatage\n",
        "print(\"🔄 Formatage des exemples...\")\n",
        "df['text'] = df.apply(format_instruction, axis=1)\n",
        "\n",
        "# Créer le dataset Hugging Face\n",
        "dataset = Dataset.from_pandas(df[['text']])\n",
        "\n",
        "# Split train/validation (80/20)\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42, shuffle=True)\n",
        "\n",
        "print(f\"✅ Dataset préparé !\")\n",
        "print(f\"   - Train : {len(dataset['train'])} exemples\")\n",
        "print(f\"   - Validation : {len(dataset['test'])} exemples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKOYXC5x3H-Y",
        "outputId": "297c159c-ea79-479b-8371-09d424221525"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧹 Préparation du dataset...\n",
            "📊 Statistiques du dataset :\n",
            "   - Total exemples : 200\n",
            "   - Colonnes : ['instruction', 'input', 'output']\n",
            "   - Exemples avec contexte : 200\n",
            "✅ Dataset correctement formaté\n",
            "🔄 Formatage des exemples...\n",
            "✅ Dataset préparé !\n",
            "   - Train : 160 exemples\n",
            "   - Validation : 40 exemples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 5 : Configuration du modèle avec LoRA\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import torch\n",
        "\n",
        "print(\"⚙️ Configuration du modèle...\")\n",
        "\n",
        "# CONFIGURATION 4-BIT (économie de mémoire)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                # Charger en 4-bit\n",
        "    bnb_4bit_quant_type=\"nf4\",        # Type de quantification\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Type de calcul\n",
        "    bnb_4bit_use_double_quant=True    # Double quantification\n",
        ")\n",
        "\n",
        "# CHOIX DU MODÈLE (2 options - choisissez une seule)\n",
        "MODEL_CHOICE = \"llama3.2-1b\"  # ⬅️ CHANGEZ ICI\n",
        "\n",
        "model_options = {\n",
        "    \"llama3.2-1b\": \"unsloth/llama-3.2-1b\",      # Léger (1B) - Recommandé pour Colab gratuit\n",
        "    \"llama3.2-3b\": \"unsloth/llama-3.2-3b\",      # Moyen (3B) - Si vous avez Colab Pro\n",
        "}\n",
        "\n",
        "model_name = model_options[MODEL_CHOICE]\n",
        "print(f\"🎯 Modèle sélectionné : {model_name}\")\n",
        "\n",
        "# Chargement du tokenizer\n",
        "print(\"📥 Chargement du tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Important !\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "print(f\"✅ Tokenizer chargé : {tokenizer.__class__.__name__}\")\n",
        "\n",
        "# %%\n",
        "# Chargement du modèle\n",
        "print(\"📥 Chargement du modèle (peut prendre 1-2 minutes)...\")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,  # 4-bit quantization\n",
        "        device_map=\"auto\",               # Auto-détection GPU\n",
        "        trust_remote_code=True,          # Nécessaire pour certains modèles\n",
        "        use_cache=False                  # Désactiver cache pour LoRA\n",
        "    )\n",
        "\n",
        "    print(\"✅ Modèle chargé avec succès !\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur chargement modèle : {e}\")\n",
        "    print(\"Essaiez un modèle plus léger (llama3.2-1b)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437,
          "referenced_widgets": [
            "74eb49d48f1d4b3f93c76666264e1cd1",
            "e215a67c15bd4e6690cb079d2cac32eb",
            "ea1d9c2df3d24bdaad88cf77acb339a8",
            "c084467944b843c9875eab86b6aebb9f",
            "3e499db25f63428294e3db0d1d12083c",
            "cb617bdc9c204ea69d282d20cbd932f1",
            "f5c8c6c58e3546aa87f0eebbdc1042ed",
            "3c6c80a1c2524cda9817a69436d83c58",
            "595b7569ac0d4e33a67db27e5eebfd73",
            "65d0f9e58e3e49a9b8b074454c3e499a",
            "b31bac2e4dc44ec99dccf9aef73452c1",
            "e156f4bc59724faca492cb5754fd2364",
            "644e862ee9a84549bb90cce6ceb0d636",
            "4770956e80b54eaf9e2a8f44fa916373",
            "6ed96c9dc5d34b2eb630845be22a42a8",
            "ea1a63a3e03e4796ba93e3c1eb655a64",
            "88f22ed5ce30421b854b8a82bcda017b",
            "f522ddc6c356454e9de2ca00e15c781a",
            "f7d27ca7976e47169eae53900157b4f6",
            "a72dd73b72764591adf3ef03153440ce",
            "1e06c8098cea44fd9560db143c6d2ce5",
            "9f5c8c0943ff4f189d5eb35e33f5e3eb",
            "f62c7ab0b5c24e5bbea6e211f951b000",
            "c2e6dd2c901d4a899f8300b819c0e7e4",
            "916d95c2cd6a410bb98438d87e15af98",
            "2d7d4d1959914cd2b442087f8ece746c",
            "6ec91e649e9e48b0b90534af787de626",
            "65b87184770441108bc657e492cfe0e0",
            "aca1c9cf7fbf4c78aa132aa4a5a9089b",
            "4a3dbc98a30d404bbe26bafe228e186b",
            "73eac46e986b49f4b0ba210c649b38c6",
            "5cb9d87d6eda489abe82d9d052c98c70",
            "0a94c2b958d843c3b7729d273570b6bf",
            "bc5cd28347d24a8f9c83cd90823d3a69",
            "eca51ed1d0dc4412b5a7562a1ccf7b31",
            "8c2eefdc6ca8453aa0f3fe6909dfc813",
            "38cfca3e1c104bb6aa9717879214bf6a",
            "9827959cb4434c4887de0080f1275a7d",
            "b937f369dff14fdca5b2c8aaff8370d1",
            "d6bb808b233e47099cdb1f92ccbbcf86",
            "8ed8601207d64471ad327e329274709d",
            "d9c06209a56a483e833ff1bd0f329314",
            "744ddeeb4c5049e3b76c73bf96ec2046",
            "6ae2e185baad40d8872587349bd4512d",
            "24dcc0ab1c364229b32bf6471cc895fb",
            "2920d516269942ffa5bf25797306b0c5",
            "775894f4d36f41cbb30330af6dd7993c",
            "a0462676639a4b2b8e83fb1440a1bb7f",
            "bfe317dba6a849bfa4b4506f80031936",
            "d98e88fb6015413795e6ead884a1e92a",
            "34e03e722aa941eeb47648ac4c03bed2",
            "84523bb27c5a4f1aae66ed3201a1954b",
            "908d1473d11c4a28973014afa590a72d",
            "13eeae2f365b434e8f0c34cb0a57fc7f",
            "bbf7deef879140abac68618cab227151",
            "59ac4efc5cf54036a627b55694eb79e9",
            "aab14732c9c148a49caad2a311dbfd38",
            "e4cc90898bfa4524af3bc523474395ec",
            "99b6502ded9443e08781578ff5e42fcb",
            "cf4d701c549c47a18722e36e74f2a3e5",
            "373c7b387e23476b9d08d9b5437e19c8",
            "5fae540bc551428da7ef65f089aef459",
            "1561868578fb4523b9b896d6f5cbe945",
            "c4cc8ebdd5b64f8aba7413b0693a71af",
            "f637337b648047199c56294e23876680",
            "4abf42418f5144cfb314a9f9747bc040"
          ]
        },
        "id": "-SwtEu3K3Woh",
        "outputId": "e2983b32-d000-4560-8e1e-3d50056ee8f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Configuration du modèle...\n",
            "🎯 Modèle sélectionné : unsloth/llama-3.2-1b\n",
            "📥 Chargement du tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74eb49d48f1d4b3f93c76666264e1cd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e156f4bc59724faca492cb5754fd2364"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f62c7ab0b5c24e5bbea6e211f951b000"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenizer chargé : PreTrainedTokenizerFast\n",
            "📥 Chargement du modèle (peut prendre 1-2 minutes)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/889 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc5cd28347d24a8f9c83cd90823d3a69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24dcc0ab1c364229b32bf6471cc895fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59ac4efc5cf54036a627b55694eb79e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle chargé avec succès !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 7 : Tokenization\n",
        "print(\"🔤 Tokenization du dataset...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize les exemples\"\"\"\n",
        "    # Tokenization avec padding/truncation\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,                # Longueur max (512-1024)\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Pour l'entraînement causal, les labels = input_ids\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "# Appliquer la tokenization\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]            # Supprimer la colonne texte originale\n",
        ")\n",
        "\n",
        "print(f\"✅ Tokenization terminée !\")\n",
        "print(f\"   - Exemple tokenizé : {len(tokenized_datasets['train'][0]['input_ids'])} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "0115b7f1efd64358b3d5473c28a8eb24",
            "736e6267bf20439a86d3cf44d593d66d",
            "6924ac252cb84d54a845cec65f231648",
            "8e4159bbce7b490bac01cd44da3159a9",
            "a27609574907484cba1c2c260faf02a2",
            "1923d8e3830e476ebdd5b2a742dae1ae",
            "d3d1557a8583403883fc2e603bb3d67a",
            "46613bc3c90c4898af764ab9fb05a1ea",
            "420daf15232448f39900846a509f57ca",
            "01ff3ae10cc24db7b919f91f6becd381",
            "0f61f0673d60413cbd1d68ccfb5cc241",
            "b26037d7799c45b9807773c80149b4b7",
            "2b7d6a12efbc45e0833772aa09a5ca73",
            "2f66f1eff94047bda4b0983372eb959b",
            "e6729801b49744ea8af5b9dc16c71cd7",
            "6959abe1c31a4b1ba209abecff823257",
            "14bee0c8997c48f59238c8b06ce3f9d3",
            "ff1b7098d7bf4693a95467b720a76fbd",
            "2919e28bc7344b7a9e1dc3a45f443635",
            "a4f2c6f052a042dcb3082bb9e92480d4",
            "637e897bfc224f7b8078f2c6e79ed741",
            "33767cc4b711461dba9c641c7967fc1d"
          ]
        },
        "id": "9lmSGpmr5JWy",
        "outputId": "892395b7-5fcc-4a8c-8e8c-7baacf42690e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔤 Tokenization du dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0115b7f1efd64358b3d5473c28a8eb24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b26037d7799c45b9807773c80149b4b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Tokenization terminée !\n",
            "   - Exemple tokenizé : 512 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 8 : Configuration de l'entraînement\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "# Créer le dossier de sortie\n",
        "output_dir = \"./emsi-llama-lora-model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"⚙️ Configuration de l'entraînement...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # Hyperparamètres d'entraînement\n",
        "    num_train_epochs=5,                # Nombre d'époques (3-10)\n",
        "    per_device_train_batch_size=2,     # Batch size (1-4 selon GPU)\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,     # Accumulation pour simuler batch plus grand\n",
        "\n",
        "    # Optimisation\n",
        "    learning_rate=2e-4,                # Taux d'apprentissage (1e-4 à 5e-4)\n",
        "    weight_decay=0.01,                 # Régularisation\n",
        "    warmup_steps=100,                  # Échauffement\n",
        "\n",
        "    # Sauvegarde et évaluation\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_total_limit=2,                # Garder seulement 2 checkpoints\n",
        "\n",
        "    # Performance\n",
        "    fp16=True,                         # Mixed precision (économise mémoire)\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "\n",
        "    # Divers\n",
        "    report_to=\"none\",                  # Pas de reporting externe\n",
        "    push_to_hub=False,                 # Pas de push sur Hugging Face\n",
        "    ddp_find_unused_parameters=False,\n",
        ")\n",
        "\n",
        "print(\"✅ Configuration d'entraînement prête !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "21B3fy7Q5P81",
        "outputId": "40d9d9f2-d961-49be-a1ec-183a7c1d01eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Configuration de l'entraînement...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4078924513.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"⚙️ Configuration de l'entraînement...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 8 : Configuration de l'entraînement\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "# Créer le dossier de sortie\n",
        "output_dir = \"./emsi-llama-lora-model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"⚙️ Configuration de l'entraînement...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # Hyperparamètres d'entraînement\n",
        "    num_train_epochs=5,                # Nombre d'époques (3-10)\n",
        "    per_device_train_batch_size=2,     # Batch size (1-4 selon GPU)\n",
        "    per_device_eval_batch_size=2,\n",
        "    gradient_accumulation_steps=4,     # Accumulation pour simuler batch plus grand\n",
        "\n",
        "    # Optimisation\n",
        "    learning_rate=2e-4,                # Taux d'apprentissage (1e-4 à 5e-4)\n",
        "    weight_decay=0.01,                 # Régularisation\n",
        "    warmup_steps=100,                  # Échauffement\n",
        "\n",
        "    # Sauvegarde et évaluation\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    eval_strategy=\"steps\",             # CHANGÉ: evaluation_strategy → eval_strategy\n",
        "    save_strategy=\"steps\",\n",
        "    save_total_limit=2,                # Garder seulement 2 checkpoints\n",
        "\n",
        "    # Performance\n",
        "    fp16=True,                         # Mixed precision (économise mémoire)\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "\n",
        "    # Divers\n",
        "    report_to=\"none\",                  # Pas de reporting externe\n",
        "    push_to_hub=False,                 # Pas de push sur Hugging Face\n",
        "    ddp_find_unused_parameters=False,\n",
        ")\n",
        "\n",
        "print(\"✅ Configuration d'entraînement prête !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4grHaq25xg2",
        "outputId": "e4da497b-eac2-4c6b-ca95-38d912e63372"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Configuration de l'entraînement...\n",
            "✅ Configuration d'entraînement prête !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 9 : Entraînement (LA PARTIE IMPORTANTE !)\n",
        "print(\"🚀 DÉBUT DE L'ENTRAÎNEMENT...\")\n",
        "print(\"⏱️  Durée estimée : 30-60 minutes\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Créer le Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        ")\n",
        "\n",
        "# Démarrer l'entraînement\n",
        "try:\n",
        "    training_results = trainer.train()\n",
        "\n",
        "    print(\"🎉 ENTRAÎNEMENT TERMINÉ !\")\n",
        "    print(f\"📈 Perte finale : {training_results.metrics['train_loss']:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur lors de l'entraînement : {e}\")\n",
        "    print(\"⚠️  Essayez les solutions suivantes :\")\n",
        "    print(\"1. Vérifiez que votre dataset est correctement formaté\")\n",
        "    print(\"2. Diminuez le batch_size (per_device_train_batch_size=1)\")\n",
        "    print(\"3. Vérifiez la mémoire disponible de votre GPU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrKGMVW-6x7r",
        "outputId": "d9de1863-38f3-47f5-8bc2-60558396277b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 DÉBUT DE L'ENTRAÎNEMENT...\n",
            "⏱️  Durée estimée : 30-60 minutes\n",
            "--------------------------------------------------\n",
            "❌ Erreur lors de l'entraînement : Attempting to unscale FP16 gradients.\n",
            "⚠️  Essayez les solutions suivantes :\n",
            "1. Vérifiez que votre dataset est correctement formaté\n",
            "2. Diminuez le batch_size (per_device_train_batch_size=1)\n",
            "3. Vérifiez la mémoire disponible de votre GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 9 : Entraînement (LA PARTIE IMPORTANTE !)\n",
        "print(\"🚀 DÉBUT DE L'ENTRAÎNEMENT...\")\n",
        "print(\"⏱️  Durée estimée : 30-60 minutes\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Créer le Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,  # Ajout important !\n",
        ")\n",
        "\n",
        "# Démarrer l'entraînement\n",
        "try:\n",
        "    training_results = trainer.train()\n",
        "\n",
        "    print(\"🎉 ENTRAÎNEMENT TERMINÉ !\")\n",
        "    print(f\"📈 Perte finale : {training_results.metrics['train_loss']:.4f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur lors de l'entraînement : {e}\")\n",
        "    print(\"\\n⚠️  Essayez de diminuer le batch_size (per_device_train_batch_size=1)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrRqK5DI7fwI",
        "outputId": "564d712f-68ad-45cb-8199-6a51a2dd237b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-759407114.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 DÉBUT DE L'ENTRAÎNEMENT...\n",
            "⏱️  Durée estimée : 30-60 minutes\n",
            "--------------------------------------------------\n",
            "❌ Erreur lors de l'entraînement : Attempting to unscale FP16 gradients.\n",
            "\n",
            "⚠️  Essayez de diminuer le batch_size (per_device_train_batch_size=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 8 : Configuration de l'entraînement\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "# Créer le dossier de sortie\n",
        "output_dir = \"./emsi-llama-lora-model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"⚙️ Configuration de l'entraînement...\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # Hyperparamètres d'entraînement\n",
        "    num_train_epochs=5,                # Nombre d'époques (3-10)\n",
        "    per_device_train_batch_size=1,     # Diminué à 1 pour éviter les erreurs\n",
        "    per_device_eval_batch_size=1,      # Diminué à 1\n",
        "    gradient_accumulation_steps=8,     # Augmenté pour compenser le batch réduit\n",
        "\n",
        "    # Optimisation\n",
        "    learning_rate=2e-4,                # Taux d'apprentissage (1e-4 à 5e-4)\n",
        "    weight_decay=0.01,                 # Régularisation\n",
        "    warmup_ratio=0.1,                  # Échauffement en ratio (au lieu de steps)\n",
        "\n",
        "    # Sauvegarde et évaluation\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_total_limit=2,                # Garder seulement 2 checkpoints\n",
        "\n",
        "    # Performance - IMPORTANT: Pas de fp16 avec 4-bit\n",
        "    # fp16=True,                       # RETIRÉ: incompatible avec 4-bit quantization\n",
        "    # fp16_full_eval=False,            # RETIRÉ aussi\n",
        "    bf16=False,                        # Désactivé aussi\n",
        "    gradient_checkpointing=True,       # Économie de mémoire\n",
        "    optim=\"paged_adamw_8bit\",          # Optimiseur spécial pour 4-bit\n",
        "\n",
        "    # Chargement du meilleur modèle\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "\n",
        "    # Divers\n",
        "    report_to=\"none\",                  # Pas de reporting externe\n",
        "    push_to_hub=False,                 # Pas de push sur Hugging Face\n",
        "    ddp_find_unused_parameters=False,\n",
        ")\n",
        "\n",
        "print(\"✅ Configuration d'entraînement prête !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKPxpoHi7w4V",
        "outputId": "f47a1fed-0f64-4e8d-e823-88e11e7f029f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Configuration de l'entraînement...\n",
            "✅ Configuration d'entraînement prête !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 9 : Entraînement (LA PARTIE IMPORTANTE !)\n",
        "print(\"🚀 DÉBUT DE L'ENTRAÎNEMENT...\")\n",
        "print(\"⏱️  Durée estimée : 30-60 minutes\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Créer le Trainer (sans tokenizer pour éviter l'avertissement)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    # tokenizer=tokenizer,  # Retiré comme suggéré par l'avertissement\n",
        ")\n",
        "\n",
        "# Démarrer l'entraînement\n",
        "try:\n",
        "    training_results = trainer.train()\n",
        "\n",
        "    print(\"🎉 ENTRAÎNEMENT TERMINÉ !\")\n",
        "    print(f\"📈 Perte finale : {training_results.metrics['train_loss']:.4f}\")\n",
        "\n",
        "    # Sauvegarder le modèle\n",
        "    print(\"💾 Sauvegarde du modèle...\")\n",
        "    trainer.save_model()\n",
        "    print(f\"✅ Modèle sauvegardé dans : {output_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur lors de l'entraînement : {e}\")\n",
        "    print(\"\\n⚠️  Solutions :\")\n",
        "    print(\"1. Vérifiez que vous avez assez de mémoire GPU\")\n",
        "    print(\"2. Diminuez encore le batch_size si nécessaire\")\n",
        "    print(\"3. Essayez avec moins d'époques (num_train_epochs=3)\")\n",
        "    print(\"4. Réduisez la longueur max des séquences (max_length=256)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8Sm8yI-7yhd",
        "outputId": "f42aeef9-ae2b-4818-8bc8-824fbfe66af9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 DÉBUT DE L'ENTRAÎNEMENT...\n",
            "⏱️  Durée estimée : 30-60 minutes\n",
            "--------------------------------------------------\n",
            "❌ Erreur lors de l'entraînement : Attempting to unscale FP16 gradients.\n",
            "\n",
            "⚠️  Solutions :\n",
            "1. Vérifiez que vous avez assez de mémoire GPU\n",
            "2. Diminuez encore le batch_size si nécessaire\n",
            "3. Essayez avec moins d'époques (num_train_epochs=3)\n",
            "4. Réduisez la longueur max des séquences (max_length=256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 5 : Configuration du modèle avec LoRA\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import torch\n",
        "\n",
        "print(\"⚙️ Configuration du modèle...\")\n",
        "\n",
        "# CONFIGURATION 4-BIT (économie de mémoire) - MODIFIÉ\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                # Charger en 4-bit\n",
        "    bnb_4bit_quant_type=\"nf4\",        # Type de quantification\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,  # CHANGÉ: float16 → bfloat16\n",
        "    bnb_4bit_use_double_quant=True    # Double quantification\n",
        ")\n",
        "\n",
        "# CHOIX DU MODÈLE\n",
        "MODEL_CHOICE = \"llama3.2-1b\"\n",
        "\n",
        "model_options = {\n",
        "    \"llama3.2-1b\": \"unsloth/llama-3.2-1b\",\n",
        "    \"llama3.2-3b\": \"unsloth/llama-3.2-3b\",\n",
        "}\n",
        "\n",
        "model_name = model_options[MODEL_CHOICE]\n",
        "print(f\"🎯 Modèle sélectionné : {model_name}\")\n",
        "\n",
        "# Chargement du tokenizer\n",
        "print(\"📥 Chargement du tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "print(f\"✅ Tokenizer chargé : {tokenizer.__class__.__name__}\")\n",
        "\n",
        "# Chargement du modèle\n",
        "print(\"📥 Chargement du modèle (peut prendre 1-2 minutes)...\")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        use_cache=False\n",
        "    )\n",
        "\n",
        "    print(\"✅ Modèle chargé avec succès !\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur chargement modèle : {e}\")\n",
        "    print(\"Essaiez un modèle plus léger (llama3.2-1b)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLJX1xby8E5h",
        "outputId": "baaf0da8-6299-4f4e-d5ba-8e4814d0fbe6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Configuration du modèle...\n",
            "🎯 Modèle sélectionné : unsloth/llama-3.2-1b\n",
            "📥 Chargement du tokenizer...\n",
            "✅ Tokenizer chargé : PreTrainedTokenizerFast\n",
            "📥 Chargement du modèle (peut prendre 1-2 minutes)...\n",
            "✅ Modèle chargé avec succès !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 8 : Configuration de l'entraînement\n",
        "from transformers import TrainingArguments, Trainer\n",
        "import os\n",
        "\n",
        "# Créer le dossier de sortie\n",
        "output_dir = \"./emsi-llama-lora-model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"⚙️ Configuration de l'entraînement...\")\n",
        "\n",
        "# D'abord, essayons avec ces paramètres optimisés\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "\n",
        "    # Hyperparamètres d'entraînement\n",
        "    num_train_epochs=3,                # Réduit à 3 époques\n",
        "    per_device_train_batch_size=1,     # Batch size minimal\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=16,    # Accumulation pour batch effectif de 16\n",
        "\n",
        "    # Optimisation\n",
        "    learning_rate=1e-4,                # Taux d'apprentissage réduit\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=50,                   # Peu d'échauffement\n",
        "\n",
        "    # Sauvegarde et évaluation\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_total_limit=2,\n",
        "\n",
        "    # Performance - CONFIGURATION SPÉCIALE\n",
        "    bf16=True,                         # Utilise bfloat16 au lieu de fp16\n",
        "    gradient_checkpointing=True,       # Économie de mémoire\n",
        "    optim=\"paged_adamw_8bit\",          # Optimiseur pour 4-bit\n",
        "\n",
        "    # Chargement du meilleur modèle\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "\n",
        "    # Divers\n",
        "    report_to=\"none\",\n",
        "    push_to_hub=False,\n",
        "    ddp_find_unused_parameters=False,\n",
        "\n",
        "    # Désactiver les avertissements de précision\n",
        "    fp16=False,                       # Explicitement désactivé\n",
        "    tf32=False,                       # Désactivé\n",
        ")\n",
        "\n",
        "print(\"✅ Configuration d'entraînement prête !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMgwGzCO8Nd2",
        "outputId": "f7cd5c41-d9df-4d90-e305-b0eb6167b6ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Configuration de l'entraînement...\n",
            "✅ Configuration d'entraînement prête !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 7 : Préparation des données\n",
        "print(\"📊 Préparation des données...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    # Réduire la longueur maximale pour économiser de la mémoire\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256  # Réduit de 512 à 256\n",
        "    )\n",
        "\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "print(\"🔠 Tokenisation des données...\")\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")\n",
        "\n",
        "print(f\"✅ Données tokenisées !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "3bb47d034a0b4af785596cbd95e855db",
            "0f6c5ba21c14442fa95932bd4934910f",
            "49a4de33d49243999c935ec2bbaac476",
            "0926b83473d541fe95ff680befe7da6a",
            "3660c55579304012b682de969a71ba2c",
            "7535ada77e6548d08b4bf06b7f829715",
            "ba167eacb81f437eaeb1abb9fcdcb471",
            "c436858fced940459b423995de871dc3",
            "be0426ce00b74667a8a5f28fa3305f77",
            "9cc40c37c2bf488dbc21a67c63718f1b",
            "c5cf029104bb47ad84c2cb8d42b83ad4",
            "98acec97afbf4eb4a678fb1372c81025",
            "b21d851c9c5f4fe4ba269a2af0bdf04e",
            "e1ced0da730044dfae4bd6ef9b901e32",
            "cfd1d2414d5042df8214fec123a42101",
            "3a7338e7abc147b5b5ddd1bec7beba02",
            "13c74d311786495caf38c4659db8be44",
            "29c2fd6f847944a8944c03e4e3c0cf43",
            "8722996dd5d64b1a950a49fe6b9e2a22",
            "a776755f9e8c492e9988449abb9af9c4",
            "e9b80980b6124eef808d8944bf8a7646",
            "065d6d8f5ae846f7874f2642d35abc65"
          ]
        },
        "id": "AzOoWe8Q8PvN",
        "outputId": "e7ab7e3e-fc1f-4b5e-fbf0-ffda13a8c2f6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Préparation des données...\n",
            "🔠 Tokenisation des données...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bb47d034a0b4af785596cbd95e855db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98acec97afbf4eb4a678fb1372c81025"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Données tokenisées !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 9 : Entraînement\n",
        "print(\"🚀 DÉBUT DE L'ENTRAÎNEMENT...\")\n",
        "print(\"⏱️  Durée estimée : 15-30 minutes\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Créer le Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    # Le tokenizer n'est plus nécessaire ici\n",
        ")\n",
        "\n",
        "# Solution alternative si ça ne marche pas\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', message='.*unscale FP16 gradients.*')\n",
        "\n",
        "# Démarrer l'entraînement\n",
        "try:\n",
        "    print(\"🔄 Démarrage de l'entraînement...\")\n",
        "    training_results = trainer.train()\n",
        "\n",
        "    print(\"🎉 ENTRAÎNEMENT TERMINÉ !\")\n",
        "    print(f\"📈 Perte finale : {training_results.metrics['train_loss']:.4f}\")\n",
        "\n",
        "    # Sauvegarder\n",
        "    trainer.save_model()\n",
        "    print(f\"💾 Modèle sauvegardé dans : {output_dir}\")\n",
        "\n",
        "except RuntimeError as e:\n",
        "    if \"unscale FP16 gradients\" in str(e):\n",
        "        print(\"⚠️  Problème de précision détecté. Tentative de solution...\")\n",
        "        # Réessayer avec une configuration encore plus simple\n",
        "        training_args.fp16 = False\n",
        "        training_args.bf16 = False\n",
        "        training_args.tf32 = False\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=tokenized_datasets[\"train\"],\n",
        "            eval_dataset=tokenized_datasets[\"test\"],\n",
        "        )\n",
        "\n",
        "        training_results = trainer.train()\n",
        "        print(\"✅ Entraînement réussi après ajustement !\")\n",
        "    else:\n",
        "        print(f\"❌ Autre erreur : {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur critique : {e}\")\n",
        "    print(\"Essayez avec un dataset plus petit ou un modèle plus léger.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "4Ct5CNZZ8VUp",
        "outputId": "a2284e07-dfc7-4bda-86b9-92aac045965c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 DÉBUT DE L'ENTRAÎNEMENT...\n",
            "⏱️  Durée estimée : 15-30 minutes\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-524480301.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Créer le Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# At this stage the model is already loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_quantized_and_base_model\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_peft_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_model_quantized_and_qat_trainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    559\u001b[0m                 \u001b[0;34m\"You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0;34m\" the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You cannot perform fine-tuning on purely quantized models. Please attach trainable adapters on top of the quantized model to correctly perform fine-tuning. Please see: https://huggingface.co/docs/transformers/peft for more details"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 5 : Configuration du modèle avec LoRA\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
        "import torch\n",
        "\n",
        "print(\"⚙️ Configuration du modèle...\")\n",
        "\n",
        "# CONFIGURATION 4-BIT (économie de mémoire)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "# CHOIX DU MODÈLE\n",
        "MODEL_CHOICE = \"llama3.2-1b\"\n",
        "\n",
        "model_options = {\n",
        "    \"llama3.2-1b\": \"unsloth/llama-3.2-1b\",\n",
        "    \"llama3.2-3b\": \"unsloth/llama-3.2-3b\",\n",
        "}\n",
        "\n",
        "model_name = model_options[MODEL_CHOICE]\n",
        "print(f\"🎯 Modèle sélectionné : {model_name}\")\n",
        "\n",
        "# Chargement du tokenizer\n",
        "print(\"📥 Chargement du tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "print(f\"✅ Tokenizer chargé : {tokenizer.__class__.__name__}\")\n",
        "\n",
        "# %%\n",
        "# Chargement du modèle\n",
        "print(\"📥 Chargement du modèle (peut prendre 1-2 minutes)...\")\n",
        "\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        "        use_cache=False\n",
        "    )\n",
        "\n",
        "    print(\"✅ Modèle chargé avec succès !\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur chargement modèle : {e}\")\n",
        "    print(\"Essaiez un modèle plus léger (llama3.2-1b)\")\n",
        "\n",
        "# %%\n",
        "# Étape 6 : PRÉPARER le modèle pour l'entraînement 4-bit + LoRA\n",
        "print(\"🔧 Préparation du modèle pour l'entraînement 4-bit...\")\n",
        "\n",
        "# IMPORTANT: Préparer le modèle pour l'entraînement k-bit\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "print(\"✅ Modèle préparé pour l'entraînement 4-bit\")\n",
        "\n",
        "# Configuration LoRA\n",
        "print(\"⚙️ Configuration LoRA...\")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "# Appliquer LoRA au modèle\n",
        "print(\"🔄 Application de LoRA au modèle...\")\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Afficher les paramètres entraînables\n",
        "model.print_trainable_parameters()\n",
        "print(\"✅ Configuration LoRA terminée !\")\n",
        "\n",
        "# %%\n",
        "# Étape 7 : Préparation des données\n",
        "print(\"📊 Préparation des données...\")\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256\n",
        "    )\n",
        "\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "print(\"🔠 Tokenisation des données...\")\n",
        "tokenized_datasets = dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=dataset[\"train\"].column_names\n",
        ")\n",
        "\n",
        "print(f\"✅ Données tokenisées !\")\n",
        "print(f\"   Train: {len(tokenized_datasets['train'])} exemples\")\n",
        "print(f\"   Test: {len(tokenized_datasets['test'])} exemples\")\n",
        "\n",
        "# %%\n",
        "# Étape 8 : Configuration de l'entraînement\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "import os\n",
        "\n",
        "# Créer le dossier de sortie\n",
        "output_dir = \"./emsi-llama-lora-model\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "print(\"⚙️ Configuration de l'entraînement...\")\n",
        "\n",
        "# Data collator pour le langage\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False  # Causal LM, pas de masquage\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=8,\n",
        "    learning_rate=2e-4,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=50,\n",
        "    logging_steps=10,\n",
        "    eval_steps=50,\n",
        "    save_steps=100,\n",
        "    eval_strategy=\"steps\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_total_limit=2,\n",
        "\n",
        "    # Désactiver fp16/bf16 pour éviter les erreurs\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "\n",
        "    gradient_checkpointing=True,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    report_to=\"none\",\n",
        "    push_to_hub=False,\n",
        "    ddp_find_unused_parameters=False,\n",
        ")\n",
        "\n",
        "print(\"✅ Configuration d'entraînement prête !\")\n",
        "\n",
        "# %%\n",
        "# Étape 9 : Entraînement\n",
        "print(\"🚀 DÉBUT DE L'ENTRAÎNEMENT...\")\n",
        "print(\"⏱️  Durée estimée : 15-30 minutes\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Créer le Trainer avec le data collator\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,  # Important pour le padding\n",
        ")\n",
        "\n",
        "# Démarrer l'entraînement\n",
        "try:\n",
        "    training_results = trainer.train()\n",
        "\n",
        "    print(\"🎉 ENTRAÎNEMENT TERMINÉ !\")\n",
        "    print(f\"📈 Perte finale : {training_results.metrics['train_loss']:.4f}\")\n",
        "\n",
        "    # Sauvegarder le modèle\n",
        "    print(\"💾 Sauvegarde du modèle...\")\n",
        "    trainer.save_model()\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    print(f\"✅ Modèle sauvegardé dans : {output_dir}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur lors de l'entraînement : {e}\")\n",
        "    print(\"\\n🔧 Solutions possibles :\")\n",
        "    print(\"1. Assurez-vous d'avoir assez de mémoire GPU\")\n",
        "    print(\"2. Essayez de réduire max_length à 128\")\n",
        "    print(\"3. Réduisez le nombre d'exemples d'entraînement\")\n",
        "    print(\"4. Utilisez un Google Colab Pro avec plus de mémoire\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694,
          "referenced_widgets": [
            "d72cf071f5104d988502d966d50d4b69",
            "ce14c0fe0f3145e4ac46405ea6e3e3a9",
            "25a26e6c0aab4533ab51f844929e537d",
            "463aea260cf64517ac29481b606bb6f5",
            "3a7882abff934c4bb5ac651445bc63e7",
            "6ddf4187940c4c1397fa0beece5830d8",
            "2a69bd8a0bb44e17930cfeda18404d19",
            "b384931ef7ca45008c8df0c875510659",
            "3aa8f4bc5c7f4c4799abe0d464be5eb3",
            "8e34871bbd0e438c974fa7fd74c3e6c3",
            "49c97b6ee50044ae9c384b9425d286b3",
            "31a306430a684ed7af01427e0ce2b0c2",
            "650424c6758a4428bb5828f459714d4c",
            "9fd9dba320e6461c8e4f87d60fb19579",
            "8b52e8f179444690a95fd61c77c46a8a",
            "52336000842c4bf9b54f45604285370d",
            "166cfe2226084ffe9a988bbba6cfa8ff",
            "3701c4e674464d38942a8e483e7ea818",
            "c1853eefda314cd4a12d3238c8cd8148",
            "b56b1a41d3ea4eea88296f9630946d81",
            "68ad6ec08d274ba1936877093c547e25",
            "45668d78a41749838f517d71d872a459"
          ]
        },
        "id": "RqThIQIn89E1",
        "outputId": "59794991-16ca-44ee-cc31-b21fa8793a2e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️ Configuration du modèle...\n",
            "🎯 Modèle sélectionné : unsloth/llama-3.2-1b\n",
            "📥 Chargement du tokenizer...\n",
            "✅ Tokenizer chargé : PreTrainedTokenizerFast\n",
            "📥 Chargement du modèle (peut prendre 1-2 minutes)...\n",
            "✅ Modèle chargé avec succès !\n",
            "🔧 Préparation du modèle pour l'entraînement 4-bit...\n",
            "✅ Modèle préparé pour l'entraînement 4-bit\n",
            "⚙️ Configuration LoRA...\n",
            "🔄 Application de LoRA au modèle...\n",
            "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n",
            "✅ Configuration LoRA terminée !\n",
            "📊 Préparation des données...\n",
            "🔠 Tokenisation des données...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d72cf071f5104d988502d966d50d4b69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31a306430a684ed7af01427e0ce2b0c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4210662833.py:165: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 128001}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Données tokenisées !\n",
            "   Train: 160 exemples\n",
            "   Test: 40 exemples\n",
            "⚙️ Configuration de l'entraînement...\n",
            "✅ Configuration d'entraînement prête !\n",
            "🚀 DÉBUT DE L'ENTRAÎNEMENT...\n",
            "⏱️  Durée estimée : 15-30 minutes\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 09:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.336400</td>\n",
              "      <td>0.271106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎉 ENTRAÎNEMENT TERMINÉ !\n",
            "📈 Perte finale : 1.2630\n",
            "💾 Sauvegarde du modèle...\n",
            "✅ Modèle sauvegardé dans : ./emsi-llama-lora-model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 10 : Sauvegarde du modèle fine-tuné\n",
        "print(\"💾 Sauvegarde du modèle...\")\n",
        "\n",
        "# Créer les dossiers de sauvegarde\n",
        "lora_dir = \"./emsi-lora-adapter\"\n",
        "full_model_dir = \"./emsi-llama-finetuned\"\n",
        "\n",
        "import os\n",
        "os.makedirs(lora_dir, exist_ok=True)\n",
        "os.makedirs(full_model_dir, exist_ok=True)\n",
        "\n",
        "# OPTION 1: Sauvegarder seulement l'adapter LoRA (léger)\n",
        "model.save_pretrained(lora_dir)\n",
        "tokenizer.save_pretrained(lora_dir)\n",
        "print(f\"✅ Adapter LoRA sauvegardé dans : {lora_dir}/\")\n",
        "print(f\"   Taille : ~{os.path.getsize(lora_dir + '/adapter_model.bin') / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# OPTION 2: Sauvegarder le modèle complet (plus lourd)\n",
        "# Note: Cela sauvegarde le modèle de base + LoRA\n",
        "trainer.save_model(full_model_dir)\n",
        "print(f\"✅ Modèle complet sauvegardé dans : {full_model_dir}/\")\n",
        "\n",
        "print(\"\\n📁 Structure des fichiers sauvegardés :\")\n",
        "print(\"1. emsi-lora-adapter/ - Adapter LoRA seulement (recommandé)\")\n",
        "print(\"   - adapter_config.json\")\n",
        "print(\"   - adapter_model.bin\")\n",
        "print(\"   - tokenizer files\")\n",
        "print(\"\\n2. emsi-llama-finetuned/ - Modèle complet\")\n",
        "print(\"   - pytorch_model.bin\")\n",
        "print(\"   - config.json\")\n",
        "print(\"   - tokenizer files\")\n",
        "\n",
        "# OPTION 3: Sauvegarder au format safetensors (plus sûr)\n",
        "try:\n",
        "    model.save_pretrained(lora_dir, safe_serialization=True)\n",
        "    print(\"\\n🔒 Version safetensors également sauvegardée\")\n",
        "except:\n",
        "    print(\"\\n⚠️  Safetensors non disponible, format PyTorch utilisé\")\n",
        "\n",
        "# Sauvegarder aussi la configuration d'entraînement\n",
        "import json\n",
        "training_config = {\n",
        "    \"model_name\": model_name,\n",
        "    \"lora_config\": lora_config.__dict__,\n",
        "    \"training_args\": training_args.to_dict(),\n",
        "}\n",
        "with open(f\"{lora_dir}/training_config.json\", \"w\") as f:\n",
        "    json.dump(training_config, f, indent=2)\n",
        "\n",
        "print(\"\\n🎉 Toutes les sauvegardes sont terminées !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "bhFNg_z8_8t_",
        "outputId": "8ed3bd52-8da7-405d-b9d1-e0d23fc7180e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Sauvegarde du modèle...\n",
            "✅ Adapter LoRA sauvegardé dans : ./emsi-lora-adapter/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './emsi-lora-adapter/adapter_model.bin'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3976353894.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlora_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"✅ Adapter LoRA sauvegardé dans : {lora_dir}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Taille : ~{os.path.getsize(lora_dir + '/adapter_model.bin') / 1024 / 1024:.1f} MB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# OPTION 2: Sauvegarder le modèle complet (plus lourd)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/genericpath.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './emsi-lora-adapter/adapter_model.bin'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 10 : Vérification et organisation de la sauvegarde\n",
        "print(\"🔍 VÉRIFICATION DE LA SAUVEGARDE...\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Chemin où le modèle a été sauvegardé (d'après votre message)\n",
        "saved_path = \"./emsi-llama-lora-model\"\n",
        "\n",
        "if os.path.exists(saved_path):\n",
        "    print(f\"✅ Modèle trouvé dans : {saved_path}\")\n",
        "\n",
        "    # Lister tous les fichiers sauvegardés\n",
        "    files = os.listdir(saved_path)\n",
        "    print(f\"📁 Fichiers sauvegardés ({len(files)} fichiers):\")\n",
        "\n",
        "    for file in sorted(files):\n",
        "        file_path = os.path.join(saved_path, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_mb = os.path.getsize(file_path) / 1024 / 1024\n",
        "            print(f\"   • {file} ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"   • {file}/ (dossier)\")\n",
        "\n",
        "    # Vérifier les fichiers importants\n",
        "    important_files = [\n",
        "        \"pytorch_model.bin\",\n",
        "        \"adapter_model.bin\",\n",
        "        \"adapter_model.safetensors\",\n",
        "        \"config.json\",\n",
        "        \"tokenizer_config.json\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n🔍 Fichiers clés trouvés :\")\n",
        "    for imp_file in important_files:\n",
        "        if imp_file in files:\n",
        "            print(f\"   ✓ {imp_file}\")\n",
        "        else:\n",
        "            # Chercher des variations\n",
        "            found = False\n",
        "            for f in files:\n",
        "                if imp_file.replace(\".bin\", \"\") in f or imp_file.replace(\".json\", \"\") in f:\n",
        "                    print(f\"   → {f} (variante de {imp_file})\")\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                print(f\"   ✗ {imp_file} (non trouvé)\")\n",
        "\n",
        "    # Calculer la taille totale\n",
        "    total_size = sum(os.path.getsize(os.path.join(saved_path, f))\n",
        "                     for f in files if os.path.isfile(os.path.join(saved_path, f)))\n",
        "    print(f\"\\n📊 Taille totale : {total_size / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "    # Créer une copie organisée (optionnel)\n",
        "    print(\"\\n🔄 Création d'une copie organisée...\")\n",
        "    organized_path = \"./emsi-llama-finetuned-organized\"\n",
        "    os.makedirs(organized_path, exist_ok=True)\n",
        "\n",
        "    # Si c'est un adapter LoRA, renommer pour plus de clarté\n",
        "    if \"adapter_config.json\" in files:\n",
        "        print(\"   Type : Adapter LoRA détecté\")\n",
        "        # Créer un README\n",
        "        with open(os.path.join(organized_path, \"README.md\"), \"w\") as f:\n",
        "            f.write(f\"\"\"# Modèle Llama 3.2 Fine-tuné avec LoRA\n",
        "\n",
        "## Spécifications\n",
        "- Modèle de base : {model_name if 'model_name' in locals() else 'llama3.2'}\n",
        "- Méthode : LoRA (Low-Rank Adaptation)\n",
        "- Perte finale : 1.2630\n",
        "- Date d'entraînement : {os.path.getctime(saved_path):%Y-%m-%d}\n",
        "\n",
        "## Utilisation\n",
        "```python\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Charger le modèle de base\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"unsloth/llama-3.2-1b\")\n",
        "\n",
        "# Charger l'adapter LoRA\n",
        "model = PeftModel.from_pretrained(base_model, \"{saved_path}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{saved_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "pHyX_BgMB5w1",
        "outputId": "c1d2bab1-d6fc-4673-e1aa-f5faa31c1909"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-1878047746.py, line 65)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1878047746.py\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    f.write(f\"\"\"# Modèle Llama 3.2 Fine-tuné avec LoRA\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 10 : Vérification et organisation de la sauvegarde\n",
        "print(\"🔍 VÉRIFICATION DE LA SAUVEGARDE...\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Chemin où le modèle a été sauvegardé (d'après votre message)\n",
        "saved_path = \"./emsi-llama-lora-model\"\n",
        "\n",
        "if os.path.exists(saved_path):\n",
        "    print(f\"✅ Modèle trouvé dans : {saved_path}\")\n",
        "\n",
        "    # Lister tous les fichiers sauvegardés\n",
        "    files = os.listdir(saved_path)\n",
        "    print(f\"📁 Fichiers sauvegardés ({len(files)} fichiers):\")\n",
        "\n",
        "    for file in sorted(files):\n",
        "        file_path = os.path.join(saved_path, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_mb = os.path.getsize(file_path) / 1024 / 1024\n",
        "            print(f\"   • {file} ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"   • {file}/ (dossier)\")\n",
        "\n",
        "    # Vérifier les fichiers importants\n",
        "    important_files = [\n",
        "        \"pytorch_model.bin\",\n",
        "        \"adapter_model.bin\",\n",
        "        \"adapter_model.safetensors\",\n",
        "        \"config.json\",\n",
        "        \"tokenizer_config.json\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n🔍 Fichiers clés trouvés :\")\n",
        "    for imp_file in important_files:\n",
        "        if imp_file in files:\n",
        "            print(f\"   ✓ {imp_file}\")\n",
        "        else:\n",
        "            # Chercher des variations\n",
        "            found = False\n",
        "            for f in files:\n",
        "                if imp_file.replace(\".bin\", \"\") in f or imp_file.replace(\".json\", \"\") in f:\n",
        "                    print(f\"   → {f} (variante de {imp_file})\")\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                print(f\"   ✗ {imp_file} (non trouvé)\")\n",
        "\n",
        "    # Calculer la taille totale\n",
        "    total_size = sum(os.path.getsize(os.path.join(saved_path, f))\n",
        "                     for f in files if os.path.isfile(os.path.join(saved_path, f)))\n",
        "    print(f\"\\n📊 Taille totale : {total_size / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "    # Créer une copie organisée (optionnel)\n",
        "    print(\"\\n🔄 Création d'une copie organisée...\")\n",
        "    organized_path = \"./emsi-llama-finetuned-organized\"\n",
        "    os.makedirs(organized_path, exist_ok=True)\n",
        "\n",
        "    # Si c'est un adapter LoRA, renommer pour plus de clarté\n",
        "    if \"adapter_config.json\" in files:\n",
        "        print(\"   Type : Adapter LoRA détecté\")\n",
        "        # Créer un README\n",
        "        with open(os.path.join(organized_path, \"README.md\"), \"w\") as f:\n",
        "            f.write(f\"\"\"# Modèle Llama 3.2 Fine-tuné avec LoRA\n",
        "\n",
        "## Spécifications\n",
        "- Modèle de base : {model_name if 'model_name' in locals() else 'llama3.2'}\n",
        "- Méthode : LoRA (Low-Rank Adaptation)\n",
        "- Perte finale : 1.2630\n",
        "- Date d'entraînement : {os.path.getctime(saved_path):%Y-%m-%d}\n",
        "\n",
        "## Utilisation\n",
        "```python\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Charger le modèle de base\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"unsloth/llama-3.2-1b\")\n",
        "\n",
        "# Charger l'adapter LoRA\n",
        "model = PeftModel.from_pretrained(base_model, \"{saved_path}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{saved_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "4uHTrWuyCIIh",
        "outputId": "cc0eca6a-1e52-465f-f6f8-b0700c37bfdc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-1878047746.py, line 65)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1878047746.py\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    f.write(f\"\"\"# Modèle Llama 3.2 Fine-tuné avec LoRA\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 10 : Vérification et organisation de la sauvegarde\n",
        "print(\"🔍 VÉRIFICATION DE LA SAUVEGARDE...\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Chemin où le modèle a été sauvegardé (d'après votre message)\n",
        "saved_path = \"./emsi-llama-lora-model\"\n",
        "\n",
        "if os.path.exists(saved_path):\n",
        "    print(f\"✅ Modèle trouvé dans : {saved_path}\")\n",
        "\n",
        "    # Lister tous les fichiers sauvegardés\n",
        "    files = os.listdir(saved_path)\n",
        "    print(f\"📁 Fichiers sauvegardés ({len(files)} fichiers):\")\n",
        "\n",
        "    for file in sorted(files):\n",
        "        file_path = os.path.join(saved_path, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_mb = os.path.getsize(file_path) / 1024 / 1024\n",
        "            print(f\"   • {file} ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"   • {file}/ (dossier)\")\n",
        "\n",
        "    # Vérifier les fichiers importants\n",
        "    important_files = [\n",
        "        \"pytorch_model.bin\",\n",
        "        \"adapter_model.bin\",\n",
        "        \"adapter_model.safetensors\",\n",
        "        \"config.json\",\n",
        "        \"tokenizer_config.json\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n🔍 Fichiers clés trouvés :\")\n",
        "    for imp_file in important_files:\n",
        "        if imp_file in files:\n",
        "            print(f\"   ✓ {imp_file}\")\n",
        "        else:\n",
        "            # Chercher des variations\n",
        "            found = False\n",
        "            for f in files:\n",
        "                if imp_file.replace(\".bin\", \"\") in f or imp_file.replace(\".json\", \"\") in f:\n",
        "                    print(f\"   → {f} (variante de {imp_file})\")\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                print(f\"   ✗ {imp_file} (non trouvé)\")\n",
        "\n",
        "    # Calculer la taille totale\n",
        "    total_size = 0\n",
        "    for f in files:\n",
        "        file_path = os.path.join(saved_path, f)\n",
        "        if os.path.isfile(file_path):\n",
        "            total_size += os.path.getsize(file_path)\n",
        "    print(f\"\\n📊 Taille totale : {total_size / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "    # Créer une copie organisée (optionnel)\n",
        "    print(\"\\n🔄 Création d'une copie organisée...\")\n",
        "    organized_path = \"./emsi-llama-finetuned-organized\"\n",
        "    os.makedirs(organized_path, exist_ok=True)\n",
        "\n",
        "    # Si c'est un adapter LoRA, renommer pour plus de clarté\n",
        "    if \"adapter_config.json\" in files:\n",
        "        print(\"   Type : Adapter LoRA détecté\")\n",
        "        # Créer un README plus simple\n",
        "        readme_content = f\"\"\"# Modèle Llama 3.2 Fine-tuné avec LoRA\n",
        "\n",
        "## Spécifications\n",
        "- Modèle de base : {\"llama3.2-1b\" if 'MODEL_CHOICE' in locals() else 'llama3.2'}\n",
        "- Méthode : LoRA (Low-Rank Adaptation)\n",
        "- Perte finale : 1.2630\n",
        "- Date : {os.path.getctime(saved_path):%Y-%m-%d}\n",
        "\n",
        "## Utilisation\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Charger le modèle de base\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"unsloth/llama-3.2-1b\")\n",
        "\n",
        "# Charger l'adapter LoRA\n",
        "model = PeftModel.from_pretrained(base_model, \"{saved_path}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{saved_path}\")\n",
        "\n",
        "## Fichiers\n",
        "- adapter_model.bin : Poids LoRA\n",
        "- adapter_config.json : Configuration LoRA\n",
        "- tokenizer* : Fichiers du tokenizer\n",
        "\"\"\"\n",
        "\n",
        "        with open(os.path.join(organized_path, \"README.md\"), \"w\") as f:\n",
        "            f.write(readme_content)\n",
        "\n",
        "    # Copier les fichiers\n",
        "    import shutil\n",
        "    try:\n",
        "        for file in files:\n",
        "            src = os.path.join(saved_path, file)\n",
        "            dst = os.path.join(organized_path, file)\n",
        "            if os.path.isfile(src):\n",
        "                shutil.copy2(src, dst)\n",
        "        print(f\"   ✅ Copie organisée créée dans : {organized_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Erreur lors de la copie : {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ Le chemin {saved_path} n'existe pas !\")\n",
        "    print(\"Tentative de recherche d'autres sauvegardes...\")\n",
        "\n",
        "    # Chercher d'autres sauvegardes possibles\n",
        "    possible_paths = [\n",
        "        \"./emsi-llama-lora-model\",\n",
        "        \"./emsi-lora-adapter\",\n",
        "        \"./output\",\n",
        "        \"./results\",\n",
        "        \"./checkpoint-*\"\n",
        "    ]\n",
        "\n",
        "    found_any = False\n",
        "    for path_pattern in possible_paths:\n",
        "        matches = glob.glob(path_pattern)\n",
        "        for match in matches:\n",
        "            if os.path.isdir(match):\n",
        "                print(f\"   Trouvé : {match}\")\n",
        "                match_files = os.listdir(match)[:5]  # Premiers 5 fichiers\n",
        "                print(f\"     Fichiers : {', '.join(match_files)}\")\n",
        "                found_any = True\n",
        "\n",
        "    if not found_any:\n",
        "        print(\"   Aucune sauvegarde trouvée\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🎉 FINE-TUNING TERMINÉ AVEC SUCCÈS !\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\n📋 Prochaines étapes :\")\n",
        "print(\"1. Tester votre modèle avec quelques exemples\")\n",
        "print(\"2. Évaluer les performances sur votre tâche\")\n",
        "print(\"3. Partager le modèle si nécessaire\")\n",
        "\n",
        "# Option : Tester rapidement le modèle\n",
        "print(\"\\n🧪 Pour tester rapidement votre modèle :\")\n",
        "print(f\"\"\"\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Charger\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"unsloth/llama-3.2-1b\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, \"{saved_path}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{saved_path}\")\n",
        "\n",
        "# Tester\n",
        "input_text = \"Votre prompt ici\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "mNF6JCeuCt5K",
        "outputId": "f05f3be7-087d-417b-b3c1-64229f809248"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 VÉRIFICATION DE LA SAUVEGARDE...\n",
            "✅ Modèle trouvé dans : ./emsi-llama-lora-model\n",
            "📁 Fichiers sauvegardés (8 fichiers):\n",
            "   • README.md (0.0 MB)\n",
            "   • adapter_config.json (0.0 MB)\n",
            "   • adapter_model.safetensors (43.0 MB)\n",
            "   • checkpoint-60/ (dossier)\n",
            "   • special_tokens_map.json (0.0 MB)\n",
            "   • tokenizer.json (16.4 MB)\n",
            "   • tokenizer_config.json (0.0 MB)\n",
            "   • training_args.bin (0.0 MB)\n",
            "\n",
            "🔍 Fichiers clés trouvés :\n",
            "   ✗ pytorch_model.bin (non trouvé)\n",
            "   → adapter_model.safetensors (variante de adapter_model.bin)\n",
            "   ✓ adapter_model.safetensors\n",
            "   → adapter_config.json (variante de config.json)\n",
            "   ✓ tokenizer_config.json\n",
            "\n",
            "📊 Taille totale : 59.5 MB\n",
            "\n",
            "🔄 Création d'une copie organisée...\n",
            "   Type : Adapter LoRA détecté\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid format specifier '%Y-%m-%d' for object of type 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3728263488.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mMéthode\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mLoRA\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mRank\u001b[0m \u001b[0mAdaptation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mPerte\u001b[0m \u001b[0mfinale\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m1.2630\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;34m-\u001b[0m \u001b[0mDate\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetctime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m## Utilisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid format specifier '%Y-%m-%d' for object of type 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 10 : Vérification et organisation de la sauvegarde\n",
        "print(\"🔍 VÉRIFICATION DE LA SAUVEGARDE...\")\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from datetime import datetime\n",
        "\n",
        "# Chemin où le modèle a été sauvegardé\n",
        "saved_path = \"./emsi-llama-lora-model\"\n",
        "\n",
        "if os.path.exists(saved_path):\n",
        "    print(f\"✅ Modèle trouvé dans : {saved_path}\")\n",
        "\n",
        "    # Lister tous les fichiers sauvegardés\n",
        "    files = os.listdir(saved_path)\n",
        "    print(f\"📁 Fichiers sauvegardés ({len(files)} fichiers):\")\n",
        "\n",
        "    for file in sorted(files):\n",
        "        file_path = os.path.join(saved_path, file)\n",
        "        if os.path.isfile(file_path):\n",
        "            size_mb = os.path.getsize(file_path) / 1024 / 1024\n",
        "            print(f\"   • {file} ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"   • {file}/ (dossier)\")\n",
        "\n",
        "    # Vérifier les fichiers importants\n",
        "    important_files = [\n",
        "        \"pytorch_model.bin\",\n",
        "        \"adapter_model.bin\",\n",
        "        \"adapter_model.safetensors\",\n",
        "        \"config.json\",\n",
        "        \"tokenizer_config.json\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n🔍 Fichiers clés trouvés :\")\n",
        "    for imp_file in important_files:\n",
        "        if imp_file in files:\n",
        "            print(f\"   ✓ {imp_file}\")\n",
        "        else:\n",
        "            # Chercher des variations\n",
        "            found = False\n",
        "            for f in files:\n",
        "                if imp_file.replace(\".bin\", \"\") in f or imp_file.replace(\".json\", \"\") in f:\n",
        "                    print(f\"   → {f} (variante de {imp_file})\")\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                print(f\"   ✗ {imp_file} (non trouvé)\")\n",
        "\n",
        "    # Calculer la taille totale\n",
        "    total_size = 0\n",
        "    for f in files:\n",
        "        file_path = os.path.join(saved_path, f)\n",
        "        if os.path.isfile(file_path):\n",
        "            total_size += os.path.getsize(file_path)\n",
        "    print(f\"\\n📊 Taille totale : {total_size / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "    # Obtenir la date de création\n",
        "    try:\n",
        "        timestamp = os.path.getctime(saved_path)\n",
        "        date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')\n",
        "    except:\n",
        "        date_str = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "    # Créer une copie organisée (optionnel)\n",
        "    print(\"\\n🔄 Création d'une copie organisée...\")\n",
        "    organized_path = \"./emsi-llama-finetuned-organized\"\n",
        "    os.makedirs(organized_path, exist_ok=True)\n",
        "\n",
        "    # Si c'est un adapter LoRA, renommer pour plus de clarté\n",
        "    if \"adapter_config.json\" in files:\n",
        "        print(\"   Type : Adapter LoRA détecté\")\n",
        "        # Créer un README plus simple\n",
        "        readme_content = f\"\"\"# Modèle Llama 3.2 Fine-tuné avec LoRA\n",
        "\n",
        "## Spécifications\n",
        "- Modèle de base : {\"llama3.2-1b\" if 'MODEL_CHOICE' in locals() else 'llama3.2'}\n",
        "- Méthode : LoRA (Low-Rank Adaptation)\n",
        "- Perte finale : 1.2630\n",
        "- Date : {date_str}\n",
        "\n",
        "## Utilisation\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Charger le modèle de base\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"unsloth/llama-3.2-1b\")\n",
        "\n",
        "# Charger l'adapter LoRA\n",
        "model = PeftModel.from_pretrained(base_model, \"{saved_path}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{saved_path}\")\n",
        "\n",
        "## Fichiers\n",
        "- adapter_model.bin : Poids LoRA\n",
        "- adapter_config.json : Configuration LoRA\n",
        "- tokenizer* : Fichiers du tokenizer\n",
        "\"\"\"\n",
        "\n",
        "        with open(os.path.join(organized_path, \"README.md\"), \"w\") as f:\n",
        "            f.write(readme_content)\n",
        "\n",
        "    # Copier les fichiers\n",
        "    import shutil\n",
        "    try:\n",
        "        for file in files:\n",
        "            src = os.path.join(saved_path, file)\n",
        "            dst = os.path.join(organized_path, file)\n",
        "            if os.path.isfile(src):\n",
        "                shutil.copy2(src, dst)\n",
        "        print(f\"   ✅ Copie organisée créée dans : {organized_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   ⚠️  Erreur lors de la copie : {e}\")\n",
        "\n",
        "else:\n",
        "    print(f\"❌ Le chemin {saved_path} n'existe pas !\")\n",
        "    print(\"Tentative de recherche d'autres sauvegardes...\")\n",
        "\n",
        "    # Chercher d'autres sauvegardes possibles\n",
        "    possible_paths = [\n",
        "        \"./emsi-llama-lora-model\",\n",
        "        \"./emsi-lora-adapter\",\n",
        "        \"./output\",\n",
        "        \"./results\",\n",
        "        \"./checkpoint-*\"\n",
        "    ]\n",
        "\n",
        "    found_any = False\n",
        "    for path_pattern in possible_paths:\n",
        "        matches = glob.glob(path_pattern)\n",
        "        for match in matches:\n",
        "            if os.path.isdir(match):\n",
        "                print(f\"   Trouvé : {match}\")\n",
        "                match_files = os.listdir(match)[:5]\n",
        "                print(f\"     Fichiers : {', '.join(match_files)}\")\n",
        "                found_any = True\n",
        "\n",
        "    if not found_any:\n",
        "        print(\"   Aucune sauvegarde trouvée\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🎉 FINE-TUNING TERMINÉ AVEC SUCCÈS !\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\n📊 Résultat : Perte finale = 1.2630\")\n",
        "print(\"✅ Votre modèle est prêt à être utilisé !\")\n",
        "\n",
        "print(\"\\n🧪 Code pour tester votre modèle :\")\n",
        "print(f\"\"\"\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# 1. Charger le modèle\n",
        "print(\"Chargement du modèle...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"unsloth/llama-3.2-1b\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "model = PeftModel.from_pretrained(base_model, \"{saved_path}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{saved_path}\")\n",
        "\n",
        "# 2. Tester\n",
        "print(\"\\\\nTest du modèle...\")\n",
        "input_text = \"Question : Quel est le capital de la France ?\\\\nRéponse :\"\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=100,\n",
        "        temperature=0.7,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(f\"Réponse : {{response}}\")\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcH04FkBDluC",
        "outputId": "d1973b2c-9c67-43dc-c294-57402ec9414a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 VÉRIFICATION DE LA SAUVEGARDE...\n",
            "✅ Modèle trouvé dans : ./emsi-llama-lora-model\n",
            "📁 Fichiers sauvegardés (8 fichiers):\n",
            "   • README.md (0.0 MB)\n",
            "   • adapter_config.json (0.0 MB)\n",
            "   • adapter_model.safetensors (43.0 MB)\n",
            "   • checkpoint-60/ (dossier)\n",
            "   • special_tokens_map.json (0.0 MB)\n",
            "   • tokenizer.json (16.4 MB)\n",
            "   • tokenizer_config.json (0.0 MB)\n",
            "   • training_args.bin (0.0 MB)\n",
            "\n",
            "🔍 Fichiers clés trouvés :\n",
            "   ✗ pytorch_model.bin (non trouvé)\n",
            "   → adapter_model.safetensors (variante de adapter_model.bin)\n",
            "   ✓ adapter_model.safetensors\n",
            "   → adapter_config.json (variante de config.json)\n",
            "   ✓ tokenizer_config.json\n",
            "\n",
            "📊 Taille totale : 59.5 MB\n",
            "\n",
            "🔄 Création d'une copie organisée...\n",
            "   Type : Adapter LoRA détecté\n",
            "   ✅ Copie organisée créée dans : ./emsi-llama-finetuned-organized\n",
            "\n",
            "==================================================\n",
            "🎉 FINE-TUNING TERMINÉ AVEC SUCCÈS !\n",
            "==================================================\n",
            "\n",
            "📊 Résultat : Perte finale = 1.2630\n",
            "✅ Votre modèle est prêt à être utilisé !\n",
            "\n",
            "🧪 Code pour tester votre modèle :\n",
            "\n",
            "from peft import PeftModel\n",
            "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
            "import torch\n",
            "\n",
            "# 1. Charger le modèle\n",
            "print(\"Chargement du modèle...\")\n",
            "base_model = AutoModelForCausalLM.from_pretrained(\n",
            "    \"unsloth/llama-3.2-1b\",\n",
            "    device_map=\"auto\",\n",
            "    torch_dtype=torch.float16\n",
            ")\n",
            "model = PeftModel.from_pretrained(base_model, \"./emsi-llama-lora-model\")\n",
            "tokenizer = AutoTokenizer.from_pretrained(\"./emsi-llama-lora-model\")\n",
            "\n",
            "# 2. Tester\n",
            "print(\"\\nTest du modèle...\")\n",
            "input_text = \"Question : Quel est le capital de la France ?\\nRéponse :\"\n",
            "inputs = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
            "\n",
            "with torch.no_grad():\n",
            "    outputs = model.generate(\n",
            "        **inputs,\n",
            "        max_new_tokens=100,\n",
            "        temperature=0.7,\n",
            "        do_sample=True\n",
            "    )\n",
            "\n",
            "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
            "print(f\"Réponse : {response}\")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Étape 11 : Test du modèle fine-tuné sur EMSI\n",
        "print(\"🧪 TEST DU MODÈLE FINE-TUNÉ EMSI\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import torch\n",
        "import textwrap\n",
        "\n",
        "# Chemin du modèle\n",
        "model_path = \"./emsi-llama-lora-model\"  # Chemin où votre modèle est sauvegardé\n",
        "base_model_name = \"unsloth/llama-3.2-1b\"  # Modèle de base utilisé\n",
        "\n",
        "print(f\"📂 Chemin du modèle : {model_path}\")\n",
        "print(f\"🤖 Modèle de base : {base_model_name}\")\n",
        "\n",
        "try:\n",
        "    # 1. Charger le tokenizer\n",
        "    print(\"\\n🔤 Chargement du tokenizer...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    print(\"✅ Tokenizer chargé\")\n",
        "\n",
        "    # 2. Charger le modèle de base\n",
        "    print(\"📥 Chargement du modèle de base...\")\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        base_model_name,\n",
        "        device_map=\"auto\",\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    print(\"✅ Modèle de base chargé\")\n",
        "\n",
        "    # 3. Charger l'adapter LoRA\n",
        "    print(\"🔗 Chargement de l'adapter LoRA...\")\n",
        "    model = PeftModel.from_pretrained(base_model, model_path)\n",
        "    model.eval()\n",
        "    print(\"✅ Adapter LoRA chargé\")\n",
        "\n",
        "    # 4. Créer le pipeline\n",
        "    print(\"⚙️ Création du pipeline...\")\n",
        "    chatbot = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        device_map=\"auto\",\n",
        "        max_new_tokens=200,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.1\n",
        "    )\n",
        "\n",
        "    print(\"🎉 Modèle EMSI fine-tuné chargé avec succès !\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erreur lors du chargement : {e}\")\n",
        "    print(\"\\n⚠️  Solutions possibles :\")\n",
        "    print(\"1. Vérifiez que le chemin du modèle est correct\")\n",
        "    print(\"2. Essayez de recharger le notebook\")\n",
        "    print(\"3. Vérifiez que vous avez assez de mémoire GPU\")\n",
        "    raise\n",
        "\n",
        "# %%\n",
        "# Questions de test spécifiques à EMSI\n",
        "print(\"\\n📝 TESTS AUTOMATIQUES EMSI :\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_questions = [\n",
        "    \"Quand a été fondée l'EMSI ?\",\n",
        "    \"Combien de campus possède l'EMSI ?\",\n",
        "    \"Le diplôme EMSI est-il reconnu par l'État ?\",\n",
        "    \"Quelles sont les spécialités disponibles à l'EMSI ?\",\n",
        "    \"Quelle est la durée des formations à l'EMSI ?\",\n",
        "    \"L'EMSI propose-t-elle des formations en alternance ?\",\n",
        "    \"Quels sont les frais de scolarité à l'EMSI ?\",\n",
        "    \"Qui est le fondateur de l'EMSI ?\",\n",
        "    \"L'EMSI a-t-elle des partenariats internationaux ?\",\n",
        "    \"Comment contacter l'EMSI ?\"\n",
        "]\n",
        "\n",
        "print(f\"🔢 {len(test_questions)} questions de test préparées\")\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    # Format du prompt (identique à celui utilisé pendant l'entraînement)\n",
        "    prompt = f\"### Question: {question}\\n\\n### Réponse:\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"❓ Question {i}/{len(test_questions)}: {question}\")\n",
        "    print(f\"{'-'*60}\")\n",
        "\n",
        "    try:\n",
        "        # Générer la réponse\n",
        "        start_time = torch.cuda.Event(enable_timing=True)\n",
        "        end_time = torch.cuda.Event(enable_timing=True)\n",
        "\n",
        "        start_time.record()\n",
        "        response = chatbot(prompt, max_new_tokens=150)[0]['generated_text']\n",
        "        end_time.record()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "        # Extraire seulement la réponse\n",
        "        if \"### Réponse:\" in response:\n",
        "            answer = response.split(\"### Réponse:\")[1].strip()\n",
        "        else:\n",
        "            answer = response.replace(prompt, \"\").strip()\n",
        "\n",
        "        # Calculer le temps\n",
        "        elapsed_time = start_time.elapsed_time(end_time) / 1000.0\n",
        "\n",
        "        # Afficher proprement\n",
        "        print(f\"💡 Réponse ({elapsed_time:.2f}s):\")\n",
        "        wrapped_answer = textwrap.fill(answer, width=70)\n",
        "        print(f\"{wrapped_answer}\")\n",
        "\n",
        "        # Évaluer la pertinence (simple)\n",
        "        keywords = question.lower().split()\n",
        "        relevant_keywords = sum(1 for keyword in keywords if keyword in answer.lower())\n",
        "        relevance_score = min(10, relevant_keywords * 2)\n",
        "        print(f\"📊 Pertinence estimée: {relevance_score}/10\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur : {e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# %%\n",
        "# Test de compréhension contextuelle\n",
        "print(\"\\n🧠 TEST DE COMPRÉHENSION CONTEXTUELLE EMSI\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "context_tests = [\n",
        "    {\n",
        "        \"context\": \"L'École Marocaine des Sciences de l'Ingénieur (EMSI) a été fondée en 1986 par M. Mohamed Kabbaj.\",\n",
        "        \"question\": \"Qui a fondé l'EMSI ?\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"L'EMSI possède 12 campus au Maroc, dont les principaux sont à Casablanca, Rabat et Marrakech.\",\n",
        "        \"question\": \"Combien de campus l'EMSI possède-t-elle ?\"\n",
        "    },\n",
        "    {\n",
        "        \"context\": \"Les diplômes de l'EMSI sont reconnus par l'État marocain et accrédités par le ministère de l'Enseignement Supérieur.\",\n",
        "        \"question\": \"Le diplôme EMSI est-il reconnu ?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for test in context_tests:\n",
        "    prompt = f\"### Contexte: {test['context']}\\n\\n### Question: {test['question']}\\n\\n### Réponse:\"\n",
        "\n",
        "    print(f\"\\n📚 Contexte: {test['context']}\")\n",
        "    print(f\"❓ Question: {test['question']}\")\n",
        "    print(f\"{'-'*50}\")\n",
        "\n",
        "    try:\n",
        "        response = chatbot(prompt, max_new_tokens=100)[0]['generated_text']\n",
        "\n",
        "        if \"### Réponse:\" in response:\n",
        "            answer = response.split(\"### Réponse:\")[1].strip()\n",
        "        else:\n",
        "            answer = response\n",
        "\n",
        "        print(f\"💡 Réponse: {answer}\")\n",
        "\n",
        "        # Vérifier si la réponse est cohérente avec le contexte\n",
        "        context_lower = test['context'].lower()\n",
        "        answer_lower = answer.lower()\n",
        "        if any(keyword in answer_lower for keyword in test['context'].split()[:5]):\n",
        "            print(\"✅ Cohérence avec le contexte: OUI\")\n",
        "        else:\n",
        "            print(\"⚠️  Cohérence avec le contexte: À vérifier\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur : {e}\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# %%\n",
        "# Test interactif\n",
        "print(\"\\n🎮 MODE INTERACTIF - Chat avec l'Assistant EMSI\")\n",
        "print(\"=\" * 50)\n",
        "print(\"💡 Tapez 'quit', 'exit' ou 'q' pour quitter\")\n",
        "print(\"💡 Tapez 'clear' pour effacer l'historique\")\n",
        "print(\"💡 Tapez 'help' pour voir les commandes disponibles\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "conversation_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\n👤 Vous: \").strip()\n",
        "\n",
        "    if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "        print(\"👋 Au revoir ! Merci d'avoir testé l'Assistant EMSI.\")\n",
        "        break\n",
        "\n",
        "    if user_input.lower() == 'clear':\n",
        "        conversation_history = []\n",
        "        print(\"🧹 Historique effacé.\")\n",
        "        continue\n",
        "\n",
        "    if user_input.lower() == 'help':\n",
        "        print(\"\\n📋 Commandes disponibles:\")\n",
        "        print(\"  - quit/exit/q : Quitter\")\n",
        "        print(\"  - clear : Effacer l'historique\")\n",
        "        print(\"  - history : Voir l'historique\")\n",
        "        print(\"  - help : Afficher cette aide\")\n",
        "        continue\n",
        "\n",
        "    if user_input.lower() == 'history':\n",
        "        print(\"\\n📜 Historique de la conversation:\")\n",
        "        for i, (q, a) in enumerate(conversation_history[-5:], 1):\n",
        "            print(f\"  {i}. Q: {q[:50]}...\")\n",
        "            print(f\"     A: {a[:50]}...\")\n",
        "        continue\n",
        "\n",
        "    # Construire le prompt avec historique\n",
        "    if conversation_history:\n",
        "        history_text = \"\\n\".join([f\"Q: {q}\\nA: {a}\" for q, a in conversation_history[-3:]])\n",
        "        prompt = f\"### Historique:\\n{history_text}\\n\\n### Nouvelle Question: {user_input}\\n\\n### Réponse:\"\n",
        "    else:\n",
        "        prompt = f\"### Question: {user_input}\\n\\n### Réponse:\"\n",
        "\n",
        "    try:\n",
        "        print(\"🤖 Assistant EMSI: \", end=\"\", flush=True)\n",
        "\n",
        "        # Générer la réponse avec stream\n",
        "        response = chatbot(prompt, max_new_tokens=200)[0]['generated_text']\n",
        "\n",
        "        if \"### Réponse:\" in response:\n",
        "            answer = response.split(\"### Réponse:\")[1].strip()\n",
        "        else:\n",
        "            answer = response\n",
        "\n",
        "        print(f\"{answer}\")\n",
        "\n",
        "        # Sauvegarder dans l'historique\n",
        "        conversation_history.append((user_input, answer))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Désolé, une erreur est survenue: {e}\")\n",
        "\n",
        "# %%\n",
        "# Évaluation finale\n",
        "print(\"\\n📊 ÉVALUATION FINALE DU MODÈLE EMSI\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'conversation_history' in locals() and conversation_history:\n",
        "    print(f\"📈 Nombre d'échanges : {len(conversation_history)}\")\n",
        "\n",
        "    # Analyser les réponses\n",
        "    total_length = 0\n",
        "    for _, answer in conversation_history:\n",
        "        total_length += len(answer.split())\n",
        "\n",
        "    if conversation_history:\n",
        "        avg_length = total_length / len(conversation_history)\n",
        "        print(f\"📏 Longueur moyenne des réponses : {avg_length:.1f} mots\")\n",
        "\n",
        "    print(\"\\n💬 Derniers échanges :\")\n",
        "    for i, (q, a) in enumerate(conversation_history[-3:], 1):\n",
        "        print(f\"\\n  Échange {i}:\")\n",
        "        print(f\"  Q: {q[:60]}...\" if len(q) > 60 else f\"  Q: {q}\")\n",
        "        print(f\"  A: {a[:60]}...\" if len(a) > 60 else f\"  A: {a}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✅ TEST DU MODÈLE EMSI TERMINÉ !\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9fudyf0FWjX",
        "outputId": "401ed482-f008-4fc7-be12-38fea39c7a18"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧪 TEST DU MODÈLE FINE-TUNÉ EMSI\n",
            "==================================================\n",
            "📂 Chemin du modèle : ./emsi-llama-lora-model\n",
            "🤖 Modèle de base : unsloth/llama-3.2-1b\n",
            "\n",
            "🔤 Chargement du tokenizer...\n",
            "✅ Tokenizer chargé\n",
            "📥 Chargement du modèle de base...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Modèle de base chargé\n",
            "🔗 Chargement de l'adapter LoRA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Adapter LoRA chargé\n",
            "⚙️ Création du pipeline...\n",
            "🎉 Modèle EMSI fine-tuné chargé avec succès !\n",
            "\n",
            "📝 TESTS AUTOMATIQUES EMSI :\n",
            "==================================================\n",
            "🔢 10 questions de test préparées\n",
            "\n",
            "============================================================\n",
            "❓ Question 1/10: Quand a été fondée l'EMSI ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (7.81s):\n",
            "La École Marocaine des Sciences de l'Ingénieur (EMSI) a été fondée en\n",
            "1986.  ## Contexte:  L'histoire de l'EMSI : une découverte importante\n",
            "## Contexte de la question:  Quand a été fondée l'EMSI?  ## Réponse\n",
            "détaillée:  **D'après les sources :** L'EMSI est un établissement\n",
            "public marocain fondé en 1986. Sa date d'inscription officielle dans\n",
            "la répartition des formations académiques passe par le décret no\n",
            "2005-27 du 30 janvier 2005. Le décret précise que l'EMSI couvre les\n",
            "📊 Pertinence estimée: 10/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 2/10: Combien de campus possède l'EMSI ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (4.35s):\n",
            "L'EMSI dispose de plus de 10 campus dans des villes différentes :\n",
            "Casablanca, Rabat, Marrakech, Tanger, Fès, Marrakech, Tanger,\n",
            "Casablanca et Rabat. Chaque campus couvre une ville spécifique avec\n",
            "des spécialisations adaptées à chaque situation.  ### Contexte:\n",
            "Statistiques de répartition des campus de l'EMSI  ### Contexte:\n",
            "Répartition des campus de l'EMSI\n",
            "📊 Pertinence estimée: 6/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 3/10: Le diplôme EMSI est-il reconnu par l'État ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (6.92s):\n",
            "Oui, le Diplôme EMSI est un équivalent officiel de baccalauréat\n",
            "scientifique international et passe en tant que telle comme\n",
            "télédémonstration dans les formations professionnels.  ## Contexte:\n",
            "**Délégation des certifications internationales de l'EMSI - Relevé des\n",
            "certificats établis**  ## Contexte détaillé:  Certification EMSI comme\n",
            "équivalent baccalauréat international  ## Réponse détaillée:  Oui, le\n",
            "Diplôme EMSI est un équivalent officiel de baccalauréat scientifique\n",
            "international et passe en tant que télédémonstration dans les\n",
            "formations professionnels. Il permet\n",
            "📊 Pertinence estimée: 6/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 4/10: Quelles sont les spécialités disponibles à l'EMSI ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (6.40s):\n",
            "Les spécialisations de l'EMSI se détaillent dans la documentation\n",
            "technique : https://www.emsi.fr/cours-de-formation/programme-courrier-\n",
            "spécialisations  ### Contexte: Fiche des formations EMSI 2024  ###\n",
            "Réponse détaillée: D'après nos sources : les étudiants passent au\n",
            "minimum 50% de credits en matières spécifiques pour passer le\n",
            "baccalauréat scientifique. Les taux d'admission varient selon la\n",
            "filière et le niveau d'études, allant généralement from 40% à 60%. Un\n",
            "système de critères de selection établi par chaque campus couvre tous\n",
            "les cas\n",
            "📊 Pertinence estimée: 6/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 5/10: Quelle est la durée des formations à l'EMSI ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (6.91s):\n",
            "L'EMSI propose des formations à temps complet (12 mois) ou semi-\n",
            "anonymes (6 mois). Toutes les formations sont couvertes par un système\n",
            "de répartition équitable des frais de scolarité.  ### Contexte:\n",
            "Modalités d'échéanclement EMSI 2024  ## Contexte : Modalités\n",
            "d'échéanclement EMSI 2024  L'École Marocaine des Sciences de\n",
            "l'Ingénieur propose plusieurs modalités d'échéanclement : le système\n",
            "semestriel avec une pause estivale, la formation annuelle avec une\n",
            "pause printanière, et des options de programmation personnalisée.\n",
            "Chaque mode d'échéanclement offre des avant\n",
            "📊 Pertinence estimée: 10/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 6/10: L'EMSI propose-t-elle des formations en alternance ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (3.83s):\n",
            "Oui, l'EMSI propose des formations en alternance avec des écoles\n",
            "d'ingénieurs privées et des entreprises publiques.  ### Contexte:\n",
            "Critères de sélection EMSI - Filières internationales 2024  ###\n",
            "Contexte détaillé:  Critères de sélection EMSI - Filières\n",
            "internationales 2024 : règlement d'admission EMSI 2024\n",
            "📊 Pertinence estimée: 10/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 7/10: Quels sont les frais de scolarité à l'EMSI ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (4.81s):\n",
            "Les frais de scolarité à l'EMSI varient selon le niveau d'études et la\n",
            "nationalité, allant généralement de 40 000 à 70 000 MAD par an. Des\n",
            "facilités de paiement sont possibles sur demande, avec un échéancier\n",
            "personnalisé adapté à chaque situation. Un service de conseils en\n",
            "financement est disponible pour les étudiants privilégiant des\n",
            "modalités de prêts étudiants ou bourses scholarships.\"\n",
            "📊 Pertinence estimée: 10/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 8/10: Qui est le fondateur de l'EMSI ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (6.72s):\n",
            "L'École Marocaine des Sciences de l'Ingénieur (EMSI) a été fondée en\n",
            "1986 par :  **Information importante :** L'EMSI est une école\n",
            "d'ingénieurs privée marocaine fondée en 1986. Son tronc commun avec\n",
            "les autres écoles d'ingénieurs privées au Maroc est l'IAMAM (Institut\n",
            "Africain des Matières Amines). Ces écoles se différencient par la\n",
            "taille, la spécialisation et la valeur ajoutée. L'EMSI a un taux\n",
            "d'admission élevé, un système de bourses attractives, et des diplômes\n",
            "académ\n",
            "📊 Pertinence estimée: 8/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 9/10: L'EMSI a-t-elle des partenariats internationaux ?\n",
            "------------------------------------------------------------\n",
            "💡 Réponse (6.95s):\n",
            "Oui, l'EMSI a plusieurs partenariats internationaux : CASIA (Chine),\n",
            "ERIC (États-Unis), IC3 (Allemagne), ISU (Russie), ISTE (Espagne), MINT\n",
            "(Afrique du Sud) et PISA (Italie).  L'EMSI développe des partenariats\n",
            "avec des institutions étrangères pour le transfert de savoirs et la\n",
            "coopération technique. Ces partenariats sont un élément important de\n",
            "la politique d'internationalisation de l'EMSI, qui vise à créer des\n",
            "réseaux de collaboration internationale, à développer les taux\n",
            "d'immigration étrangère et à offrir une\n",
            "📊 Pertinence estimée: 8/10\n",
            "\n",
            "\n",
            "============================================================\n",
            "❓ Question 10/10: Comment contacter l'EMSI ?\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💡 Réponse (6.47s):\n",
            "Pour les questions concernant l'emsi : le service client EMSI est\n",
            "accessible sur demande au 04 72 46 10 00 ou via email à\n",
            "[email protected]. pour les réponses détaillées veuillez consulter la\n",
            "page web officielle de l'emsi : https://www.emsi.fr/fr/contact/  ###\n",
            "Contexte:  Département des relations publiques de l'emsi - contactez-\n",
            "nous  ### Contexte détaillé:  Pour les questions concernant l'emsi :\n",
            "le service client emsi est accessible sur demande au 04 72 46 10 00 ou\n",
            "via email à [email protected]. pour les réponses détaillées veu\n",
            "📊 Pertinence estimée: 2/10\n",
            "\n",
            "\n",
            "🧠 TEST DE COMPRÉHENSION CONTEXTUELLE EMSI\n",
            "==================================================\n",
            "\n",
            "📚 Contexte: L'École Marocaine des Sciences de l'Ingénieur (EMSI) a été fondée en 1986 par M. Mohamed Kabbaj.\n",
            "❓ Question: Qui a fondé l'EMSI ?\n",
            "--------------------------------------------------\n",
            "💡 Réponse: L'EMSI a été fondée en 1986 par :\n",
            "\n",
            "**Monsieur Mohamed Kabbaj**, un éminent enseignant marocain, débute sa carrière comme professeur au CIDEA de Casablanca en 1967. Il passe plusieurs années à l'EMSI comme directeur du département de mathématiques et de la formation professionnelle ou comme consultant technique dans le secteur de l'éducation nationale. Son engagement professionnel\n",
            "✅ Cohérence avec le contexte: OUI\n",
            "\n",
            "\n",
            "📚 Contexte: L'EMSI possède 12 campus au Maroc, dont les principaux sont à Casablanca, Rabat et Marrakech.\n",
            "❓ Question: Combien de campus l'EMSI possède-t-elle ?\n",
            "--------------------------------------------------\n",
            "💡 Réponse: L'EMSI dispose de 12 campus dans le Maroc : Casablanca (siège), Rabat, Marrakech, Tanger, Fès, Meknès, Rabat-Salé, Casablanca-Al Hoceima, Marrakesh-Tensift-Ouadaïd, Marrakech-Roumia, Tanger-Med, and Salé. Ces campus représentent une infrastructure moderne avec des laboratoires modernes, salles\n",
            "✅ Cohérence avec le contexte: OUI\n",
            "\n",
            "\n",
            "📚 Contexte: Les diplômes de l'EMSI sont reconnus par l'État marocain et accrédités par le ministère de l'Enseignement Supérieur.\n",
            "❓ Question: Le diplôme EMSI est-il reconnu ?\n",
            "--------------------------------------------------\n",
            "💡 Réponse: Oui, les diplômes EMSI sont reconnus et accredités par la MOHE et le MEES au Maroc. Ils sont valides dans tout le pays. La valeur ajoutée des diplômes EMSI dépasse celle des diplômes étrangers en termes d'équipements, d'instruments, de laboratoires et d'encadrement.\"\n",
            "✅ Cohérence avec le contexte: OUI\n",
            "\n",
            "\n",
            "🎮 MODE INTERACTIF - Chat avec l'Assistant EMSI\n",
            "==================================================\n",
            "💡 Tapez 'quit', 'exit' ou 'q' pour quitter\n",
            "💡 Tapez 'clear' pour effacer l'historique\n",
            "💡 Tapez 'help' pour voir les commandes disponibles\n",
            "--------------------------------------------------\n",
            "\n",
            "👤 Vous: q\n",
            "👋 Au revoir ! Merci d'avoir testé l'Assistant EMSI.\n",
            "\n",
            "📊 ÉVALUATION FINALE DU MODÈLE EMSI\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "✅ TEST DU MODÈLE EMSI TERMINÉ !\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# TÉLÉCHARGEMENT DU MODÈLE\n",
        "print(\"💾 TÉLÉCHARGEMENT DU MODÈLE FINE-TUNÉ\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Chemin de votre modèle\n",
        "model_path = \"./emsi-llama-lora-model\"\n",
        "output_zip = \"emsi-llama-model.zip\"\n",
        "\n",
        "# Vérifier que le modèle existe\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"❌ Erreur : Le modèle n'existe pas dans {model_path}\")\n",
        "    print(\"📁 Dossiers disponibles :\")\n",
        "    for item in os.listdir(\".\"):\n",
        "        if os.path.isdir(item):\n",
        "            print(f\"  • {item}\")\n",
        "else:\n",
        "    print(f\"✅ Modèle trouvé : {model_path}\")\n",
        "    print(f\"📊 Taille du dossier : {sum(os.path.getsize(os.path.join(model_path, f)) for f in os.listdir(model_path) if os.path.isfile(os.path.join(model_path, f))) / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "    # Option 1 : Zipper et télécharger\n",
        "    print(\"\\n📦 Méthode 1 : Compression en ZIP\")\n",
        "    try:\n",
        "        shutil.make_archive(\"emsi-llama-model\", 'zip', model_path)\n",
        "        print(f\"✅ ZIP créé : emsi-llama-model.zip\")\n",
        "\n",
        "        # Télécharger\n",
        "        print(\"⬇️  Téléchargement du fichier ZIP...\")\n",
        "        files.download(\"emsi-llama-model.zip\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erreur lors de la compression : {e}\")\n",
        "\n",
        "    # Option 2 : Télécharger fichier par fichier\n",
        "    print(\"\\n📁 Méthode 2 : Télécharger les fichiers individuellement\")\n",
        "    important_files = []\n",
        "    for file in os.listdir(model_path):\n",
        "        if file.endswith(('.bin', '.json', '.txt', '.md', '.safetensors')):\n",
        "            important_files.append(file)\n",
        "\n",
        "    print(f\"📄 {len(important_files)} fichiers importants trouvés :\")\n",
        "    for file in important_files:\n",
        "        print(f\"  • {file}\")\n",
        "\n",
        "    # Télécharger les fichiers importants\n",
        "    for file in important_files:\n",
        "        try:\n",
        "            shutil.copy(os.path.join(model_path, file), file)\n",
        "            files.download(file)\n",
        "            os.remove(file)  # Nettoyer\n",
        "            print(f\"  ✅ {file} téléchargé\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ❌ Erreur pour {file}: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"🎉 TÉLÉCHARGEMENT PRÊT !\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "xU3We3iwGaGg",
        "outputId": "1c7450ff-9481-4958-a84c-19c47194d2f7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 TÉLÉCHARGEMENT DU MODÈLE FINE-TUNÉ\n",
            "==================================================\n",
            "✅ Modèle trouvé : ./emsi-llama-lora-model\n",
            "📊 Taille du dossier : 59.5 MB\n",
            "\n",
            "📦 Méthode 1 : Compression en ZIP\n",
            "✅ ZIP créé : emsi-llama-model.zip\n",
            "⬇️  Téléchargement du fichier ZIP...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b110f71c-d48b-4ea4-ab04-f028462d23ad\", \"emsi-llama-model.zip\", 109357855)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📁 Méthode 2 : Télécharger les fichiers individuellement\n",
            "📄 7 fichiers importants trouvés :\n",
            "  • adapter_model.safetensors\n",
            "  • special_tokens_map.json\n",
            "  • adapter_config.json\n",
            "  • tokenizer.json\n",
            "  • training_args.bin\n",
            "  • tokenizer_config.json\n",
            "  • README.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e75f5b7c-6e33-4a8c-ad53-ebee0b6ab0c8\", \"adapter_model.safetensors\", 45118424)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ adapter_model.safetensors téléchargé\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0099e409-09d4-4784-8a21-c44cd97390ae\", \"special_tokens_map.json\", 335)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ special_tokens_map.json téléchargé\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8d0430f0-4032-4c91-a9c3-196f8ab18c0f\", \"adapter_config.json\", 1050)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ adapter_config.json téléchargé\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9341a6f4-0a76-47a4-af31-f9cda75b884f\", \"tokenizer.json\", 17210200)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ tokenizer.json téléchargé\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1e98e356-2ee9-4056-a0fd-984713b2a3d7\", \"training_args.bin\", 5841)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ training_args.bin téléchargé\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d4907ff1-097e-43c6-81b0-b1cb3df01bec\", \"tokenizer_config.json\", 50637)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ tokenizer_config.json téléchargé\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8128e526-69f6-41f1-8e62-da98619c2036\", \"README.md\", 5194)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✅ README.md téléchargé\n",
            "\n",
            "==================================================\n",
            "🎉 TÉLÉCHARGEMENT PRÊT !\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}